[{"title":"【翻译】Unity的TransformAccessArray —— 内部机制与最佳实践","date":"","description":"文章的翻译","body":"\u0026ldquo;Unity’s TransformAccessArray — internals and best practices\u0026quot;文章的翻译\n声明 原文地址：https://medium.com/toca-boca-tech-blog/unitys-transformaccessarray-internals-and-best-practices-2923546e0b41\n本文翻译如有侵权，请及时联系笔者。\n我最近接手了一位转组同事留下的渲染代码，这些代码大量使用了 Unity 的 TransformAccessArray 和 Unity Jobs。我之前听说过 TransformAccessArray，也见过它的使用，但从未有机会深入了解它的工作原理。\n要搞懂它确实有点吃力，因为相关资料非常少，Unity官方文档也很简略。截至目前，最有用的文档页面是IJobParallelForTransform和IJobParallelForTransformExtensions的子页面，但即使是这些页面，内容也不够详尽。\n因此，这次正好是一个机会，让我深入研究 Unity Job System 的一些内部机制，以更好地理解 TransformAccessArray 和 IJobParallelForTransform 的工作原理，特别是它们与主线程上的“常规” Transform 访问之间的交互。我发现了一些非常有趣的结果，想在这篇文章中分享给大家。\n接下来，我将介绍TransformAccessArray的一些内部机制、一个用于测试的Job脚本、几种Job使用模式的分析:具有Job依赖的TransformAccessArrayJob、多次只读Transform访问、单个Transform根节点，以及基于这些观察得出的最佳实践。文章最后还有一个简短的Unity性能优化愿望清单，希望能推动Job System的性能提升。\n让我们开始吧！\nTransformAccessArray的内部机制 Unity的Job System只能使用blittable的数据类型，这意味着 Job 无法访问托管类型（如 Transform 和 MeshRenderer）。从安全性角度来看，这种限制可以防止数据竞争：即一个工作线程在写入某块内存时，另一个线程或主线程也在访问该内存地址。\nTransformAccessArray 提供了一种绕过这一限制的方法，使得 Job 可以读取或写入 Transform 数据。其核心功能依赖于 Unity 内部的 C++ 类 TransformHierarchy。在Unite Berlin 2018 — Unity’s Evolving Best Practices演讲的 13:14 处，有一段关于该类的讨论，至今仍然非常相关。以下这句话非常关键，有助于理解 TransformAccessArray 的工作原理：\n场景中的每个transform root都有一个对应的transform hierarchy。\n场景层级中的transform root\n从此处开始，我将交替使用“transform hierarchy（transform层级结构）”和“transform root（transform根节点）”这两个术语。\n如果将上述内容与这段在IJobParallelForTransform.Schedule文档中的片段结合起来，我们可以初步感受到两者之间的联系：\n该方法对不同层级结构中的Transform进行并行访问。共享同一个根对象的 Transform总是在同一个线程上处理。\n而ScheduleReadOnly方法则放宽了调度限制：\n该方法提供了更好的并行性，因为它可以并行读取所有 Transform，而不仅仅是不同层级结构之间的并行。\n当你使用一个 Transform 数组创建 TransformAccessArray 实例时，Unity 会在内部对其进行重排序，以提高访问效率。Transform 首先会按根节点进行分组，然后共享同一个根节点的 Transform 会被排序在一起，以便根据其内部的层级结构优化迭代速度。\n当 Unity 执行 IJobParallelForTransform Job 时，它调用 Execute 方法的顺序可能与 TransformAccessArray 中 Transform 数组的原始顺序完全不同。这时，index 参数就派上用场了。它允许你将某次 Execute 调用映射回原始 Transform 数组中的对应元素。如果你注意到内部方法 TransformAccessArray.GetSortedToUserIndex 并好奇它的作用，这就是答案。\n重要的是，TransformAccessArray 不会为了读取或写入 Transform 数据而复制任何数据。除非你以其他方式实现，否则不会有缓冲区或临时存储。这种直接访问是使用它的主要好处。\n但这也意味着，在我们具体了解这一切如何协同工作之前，还有一段理论需要掌握。\nTransform 层级访问的同步机制 如前文所述，Unity 的Job System对Job中可以访问的数据有非常严格的限制。对于 TransformAccessArray 及其隐式提供的 TransformHierarchy 实例，这意味着 Unity 必须有一些机制来避免并发修改 Transform 或读取过期值。其数据同步方法（内部称为 fence）可防止主线程和工作线程同时访问同一 Transform 时发生竞争条件。\nUnity 保护 Transform 访问的颗粒度是 Transform 层级结构。换句话说，所有共享同一个 Transform 根节点的 Transform 也共享同一个 fence。当一个使用 TransformAccessArray 的 Job 被调度时，Unity 会延迟所有对该 Job 所涉及的 Transform 层级结构中任何 Transform 的访问，直到该 Job 完成。这意味着，任何与该 TransformAccessArray 中任意 Transform 共享同一个根节点的 Transform，都会被阻塞。让我们用一个例子来说明：\n两个操作同一 Transform 层级结构的 Job 上图展示了两个 Job，即使它们访问的不是同一个 Transform，只要它们共享一个 Transform 层级结构，就会发生阻塞。如果 Job A 在 Job B 之前被调度，那么 Job B 必须等到 Job A 完成后才能开始。即使 Job A 剩余的任务只涉及其他层级结构，它也必须完全完成。这种阻塞行为会影响以下场景：\n其他 IJobParallelForTransform Job，即使是只读 Job。 主线程对 Transform 的读取或写入，例如在 MonoBehaviour 脚本中。 任何其他对 Transform 的访问，例如动画和蒙皮网格渲染器。 当 Job 被阻塞时，它们会留在 Job 执行队列中。当主线程被阻塞时（例如调用JobHandle.Complete 或尝试访问一个尚未完成的 Job 正在使用的 Transform），它可能会空闲下来，或者可能的情况下窃取工作。而工作窃取意味着主线程会拿起一个准备执行的 Job 并执行它。其背后的逻辑是：主线程做点事总比闲着好。但这会带来一些重要后果，后文会讨论。\nTransformAccessArray测试脚本 我写了以下测试脚本，用于验证我前面提到的很多信息，并在不同的人造Job场景（译注：表明这些场景都是特意制造出来的）中验证我对 TransformAccessArray 的理解。没有哪个游戏会真的按这个顺序执行这些操作，但它仍然是模拟各种真实场景的好方法。\n（代码已针对 Medium 的窄屏宽度优化显示）\nusing System.Threading; using Unity.Jobs; using Unity.Profiling; using UnityEngine; using UnityEngine.Jobs; public class TransformAccessArrayTest : MonoBehaviour { [SerializeField] [Range(1, 100)] private uint hierarchyRootsCount = 2; [Tooltip(\u0026#34;Transform count in each transform hierarchy root\u0026#34;)] [SerializeField] [Range(1, 100)] private uint hierarchyDepth = 4; [Tooltip(\u0026#34;How long to delay the start of the TransformJob\u0026#34;)] [SerializeField] private int delayJobStartMs; [Tooltip(\u0026#34;Per-Transform job time\u0026#34;)] [SerializeField] private int jobRuntimeMs = 1; [SerializeField] [Range(-1, 100)] private int desiredJobCount = -1; [SerializeField] private bool scheduleAsReadOnlyJob; [Tooltip(\u0026#34;Schedule a second read-only IJobParallelForTransform job\u0026#34;)] [SerializeField] private bool addParallelReadOnlyJob; [Tooltip(\u0026#34;Applies to read-only jobs only\u0026#34;)] [Range(1, 100)] [SerializeField] private int readonlyJobBatchSize = 2; [SerializeField] private bool readTransformsAfterJob = true; [SerializeField] private bool writeTransformsAfterJob; GameObject[] generatedGameObjects; TransformAccessArray accessArray; static readonly ProfilerMarker markerBefore = new(\u0026#34;BeforeJobScheduled\u0026#34;); static readonly ProfilerMarker markerReadAfter = new(\u0026#34;ReadAfterJobScheduled\u0026#34;); static readonly ProfilerMarker markerWriteAfter = new(\u0026#34;WriteAfterJobScheduled\u0026#34;); void OnValidate() =\u0026gt; Cleanup(); void OnDestroy() =\u0026gt; Cleanup(); void Cleanup() { if (generatedGameObjects != null) { for (int i = generatedGameObjects.Length - 1; i \u0026gt;= 0; i--) Destroy(generatedGameObjects[i]); generatedGameObjects = null; if (accessArray.isCreated) accessArray.Dispose(); } } void Update() { // Support dynamically changing parameters in the Editor if (!accessArray.isCreated) CreateTransformArray(); // Write to the transforms from the main thread using (markerBefore.Auto()) { foreach (var go in generatedGameObjects) go.transform.position += new Vector3(0.000001f,0, 0); } var delayJobHandle = delayJobStartMs \u0026lt;= 0 ? default : new DelayJob() { DelayMs = delayJobStartMs }.Schedule(); var transformJob = new TransformJob() { JobRuntimeMs = jobRuntimeMs }; // Set the optional DelayJob as a job dependency of TransformJob if (scheduleAsReadOnlyJob) { transformJob.ScheduleReadOnly(accessArray, readonlyJobBatchSize, delayJobHandle); } else { transformJob.Schedule(accessArray, delayJobHandle); } // Schedule a second read-only job if (addParallelReadOnlyJob) { new ReadOnlyJob() { JobRuntimeMs = jobRuntimeMs } .ScheduleReadOnly(accessArray, readonlyJobBatchSize, delayJobHandle); } // Fake some work so the loops below can\u0026#39;t be removed as no-ops var position = Vector3.zero; if (readTransformsAfterJob) { using var _ = markerReadAfter.Auto(); foreach (var go in generatedGameObjects) position += go.transform.position; } if (writeTransformsAfterJob) { using var _ = markerWriteAfter.Auto(); position = Vector3.Min(position * 0.0000001f, Vector3.one * 0.1f); foreach (var go in generatedGameObjects) go.transform.position = position; } } void CreateTransformArray() { generatedGameObjects = new GameObject[hierarchyRootsCount * hierarchyDepth]; var transforms = new Transform[hierarchyRootsCount * hierarchyDepth]; var transformsIndex = 0; for (int i = 0; i \u0026lt; hierarchyRootsCount; i++) { var parent = new GameObject($\u0026#34;generated_{i}\u0026#34;); generatedGameObjects[transformsIndex] = parent; transforms[transformsIndex++] = parent.transform; // Not technically a depth, but it has the same impact // for Unity\u0026#39;s job scheduling for (int j = 0; j \u0026lt; hierarchyDepth - 1; j++) { var child = new GameObject($\u0026#34;{parent.name}_{j}\u0026#34;); child.transform.SetParent(parent.transform); generatedGameObjects[transformsIndex] = child; transforms[transformsIndex++] = child.transform; } } accessArray = new TransformAccessArray(transforms, desiredJobCount); } } struct DelayJob : IJob { public int DelayMs; public void Execute() =\u0026gt; Thread.Sleep(DelayMs); } struct TransformJob : IJobParallelForTransform { public int JobRuntimeMs; public void Execute(int i, TransformAccess t) =\u0026gt; Thread.Sleep(JobRuntimeMs); } // Use a second type to easily identify it in the profiler struct ReadOnlyJob : IJobParallelForTransform { public int JobRuntimeMs; public void Execute(int i, TransformAccess t) =\u0026gt; Thread.Sleep(JobRuntimeMs); } 脚本启动时，会根据 Hierarchy Roots Count 和 Hierarchy Depth 属性生成一个游戏对象层级结构。\n脚本属性与生成的场景游戏对象\n下面的序列图展示了 Update 方法的执行流程，黄色框展示了某些属性的影响。\nJob与行为的序列图\n如果启用 Add Parallel Read Only Job 属性，脚本会在序列图的第二步之后立即调度第二个 IJobParallelForTransform Job，即 ReadOnlyJob。为了简化脚本，该 Job 访问的是同一个 TransformAccessArray，但即使它们使用不同的 TransformAccessArray 实例，只要访问的是同一个 Transform 层级结构，结果也是一样的。\nDelayJob 是一个可选的 Job 依赖项，它允许我们模拟某些 Job 依赖其他 Job 输出的场景（尽管本脚本中并没有实际输出）。\n我们使用 -job-worker-count 4 命令行参数（译注：Unity Hub可以在工程项添加）将 Unity 配置为使用 4 个工作线程，来分析几种场景。\n具有Job依赖的TransformAccessArrayJob 本场景使用 2 个 Transform 根节点，每个根节点下有 4 个 Transform。测试脚本调度了一个 DelayJob，它是 TransformJob 和 ReadOnlyJob 的依赖项。\n带 Job 依赖的 TransformAccessArray Job 设置\n带 Job 依赖的 TransformAccessArray Job的Profiler截图\n从 Profiler 截图中我们可以观察到几点：\n主线程在 ReadAfterJobScheduled 中被阻塞，因为它试图读取 TransformJob 和 ReadOnlyJob 正在使用的 Transform。注意，主线程是在 DelayJob 执行期间被阻塞的，而 DelayJob 并不是 IJobParallelForTransform。这是因为 TransformJob 已经被调度执行，此时它已经将自身设置为该 Transform 层级结构同步 fence 的依赖项。\n当主线程被阻塞时，Profiler 截图展示了上述两种行为：主线程先“偷取”并执行了 DelayJob，然后在其他 Job 执行期间处于空闲状态。这种行为是非确定性的，在不同帧之间可能会有所不同。\n尽管 Desired Job Count 设置为 8，而总共有 8 个 Transform 可供处理，但 TransformJob 只分成了 2 个批次。这是因为非只读 Job 不会在同一 Transform 层级结构上并行执行。而 ReadOnlyJob 可以在同一层级结构上并行访问 Transform，因此被分成了 4 个批次（因为 Read Only Batch Size 设置为 2）。\n多次只读TransformAccesses 本场景使用相同的 Transform 配置，但 TransformJob 和 ReadOnlyJob 都是只读 Job，并且没有 DelayJob（下一节会解释原因）。换句话说，在 BeforeJobScheduled 标记的写入访问之后，脚本只通过只读方式访问 Transform。\n多次只读 transform accesses的设置\n多次只读 transform accesses的Profiler截图\n_\n主线程再次在 ReadAfterJobScheduled 中被阻塞，因为它试图读取正在由 Job 使用的 Transform。我对这种阻塞行为感到惊讶，因为这些访问都是只读的，而且 Unity 可以通过 API 调用清楚地知道这一点。\n这是 Unity 错过的一个优化机会：允许多个只读用户并行访问共享资源。理论上，Unity 可以让主线程无阻塞地读取 Transform 数据，并与其他只读 Job 并行运行，而不是让线程空闲。\n死锁警告！ 截至目前，以下问题影响 Unity 版本 2022.3.31f1 至 2022.3.52f1，以及 6000.0.3f1 及以上版本。\n如果你在上一场景中设置 Delay Job Start 为非零值，Unity 将会卡死无响应。ReadAfterJobScheduled 中的 Transform 读取访问永远不会完成，陷入死锁。\n导致死锁的最小事件顺序如下：\n调度任意 Job A。 使用 ScheduleReadOnly 方法调度一个 IJobParallelForTransform 的Job B，它依赖于 Job A。 从主线程读取包含在 Job B 的 TransformAccessArray 中的某个 Transform 的位置。 这是一个常见的 Job 使用模式，但由于依赖于具体的执行时机，这个 Bug 可能是间歇性的，难以在实际项目中诊断。\n在我们分析《Toca Boca Days》游戏的“应用无响应”（ANR）问题时，最常见的调用栈就出现在访问 Transform 的代码中。由于我们大量使用了 IJobParallelForTransform.ScheduleReadOnly，我怀疑我在研究 TransformAccessArray 时，偶然发现了这些卡死的根本原因。 意外收获！\n相关 Unity 工单：UUM-86782。\n单个Transform根节点 我们再来看一个场景：只有一个根 Transform，但有很多子对象。我们将 Desired Job Count 设置为 -1，让 Unity 自己选择默认值。\n单个根 Transform 的设置\n单个根 Transform 的Profiler截图\n__\n如前所述，主线程在 ReadAfterJobScheduled 中被阻塞。\n由于 TransformJob 不是以只读方式调度的，而且整个 TransformAccessArray 只有一个 Transform 层级结构，Unity 不会将该 Job 分发到多个工作线程，导致 Job 执行时间非常长。\n而 ReadOnlyJob 不受层级结构数量限制，被分成了 4 个较小的单元。不过，在某些帧中，ReadOnlyJob 会同时有 4 个或 5 个任务在执行。这种差异是因为 TransformParallelForLoopStruct.Execute 方法（这是每个线程在 C# 中的 Job 起始点）会调用 JobsUtility.GetWorkStealingRange 来“偷取”其他线程的任务批次，直到所有任务完成。由于线程到达该代码的顺序是非确定性的，理论上我们可能会看到 1 到 5 个线程在执行该 Job。\nTransformAccessArray Job 性能最佳实践 以下是基于我的研究和分析得出的建议，适用于 Unity 2022.3.52f1 和 6000.0.26f1 版本。这些建议可以帮助你更好地利用 TransformAccessArray Job。\n关于 Job System 的一般性最佳实践还有很多内容，但本文重点聚焦于访问 Transform 的 Job。我还是要给出一条通用建议：尽量使用Burst 编译器。我的示例代码中没有使用它，因为它与我的研究无关，但在实际项目中你几乎总是应该使用它。\n1. 使用 ScheduleReadOnly 调度只读 Job 如果一个 Job 只需要读取 Transform 数据（即不写入），请务必使用 IJobParallelForTransform.ScheduleReadOnly 方法来调度它。这样可以获得更好的并行性。不过，请务必阅读前面的“死锁警告！”部分，因为当前 Unity 版本中存在一个严重的 Bug。\n2. 避免深层次的 Transform 层级结构 尽可能将深层次的 Transform 层级结构拆分为多个根 Transform。务必避免“文件夹”式层级结构（即大量游戏对象挂在一个根节点下）。这条建议对 Unity 的许多系统和性能都有显著影响。对于使用 TransformAccessArray 的 Job，具体好处包括：\n为非只读 Job 提供更多并行化机会。Job System 不会将这类 Job 分发到更多（超过Transform 根节点数量）的工作线程上。【注：有n个根节点，那么最多只能分发到n个工作线程并行处理】 降低 Job 无意中阻塞主线程或产生“隐式” Job 依赖的可能性。记住，只要一个 Job 访问了某个 Transform 层级结构，而另一个 Job 也访问了同一个层级结构，那么后者必须等前者完成，即便它是只读的。 3. 在真机上分析 Job 行为 在目标硬件或代表性设备上，使用 Profiler 分析游戏中 Job 的行为。不同平台和构建配置下的性能瓶颈可能完全不同。如果你发现某些帧中，TransformAccessArray Job 的工作线程数量少于预期，请检查是否有限制并行性的因素，并审查你使用的 desiredJobCount 和 innerloopBatchCount 参数。你应设置足够小的值以保持所有工作线程忙碌，但又不能太小，以免线程频繁地抓取或偷取任务。这里没有放之四海而皆准的值。作为参考，Unity 默认为非只读 Job 设置的最小 Transform 数量为 32，而所有并行 Job 的最大任务批次数量为 16。\n4. 优先使用局部空间数据 尽可能使用局部空间的 Transform 数据，例如 localPosition 和 GetLocalPositionAndRotation，而不是世界空间数据，如 position 和 localToWorldMatrix。这条建议适用于所有与 Transform 交互的场景，而不仅仅是 Job。Transform 层级结构存储的是局部空间的变换矩阵，因此局部空间值可以直接访问。而世界空间值需要 Unity 递归地乘以所有父节点的局部矩阵，每次访问时都会重新计算。这个过程比直接访问局部空间值慢得多，且随着父节点数量增加而变得更慢。如果必须使用世界空间值，请尽量减少调用次数，并使用 GetPositionAndRotation 和 SetPositionAndRotation。\n5. 重用 TransformAccessArray 实例 在帧之间重用 TransformAccessArray 实例，不要无谓地重新创建。每次创建新实例时，Unity 都会分配内存、准备状态并对 Transform 进行排序，这些都会耗时。例如，如果你需要从数组中移除一个 Transform，请使用 TransformAccessArray.RemoveAtSwapBack 方法，而不是重新创建数组。不过，这里有一个关于 fence 的注意事项：当你修改一个已有的 TransformAccessArray 时，Unity 会触发一个同步点，等待所有之前使用该数组的 Job 完成。因此，也不要为了重用数组而引入隐式的 Job 依赖。\n6. 不要用 Transform 存储中间数据 不要使用 TransformAccessArray 中的 Transform 来存储 Job 之间的中间数据。与其他方式相比，Job 中访问 Transform 的速度相对较慢，且有阻塞主线程的风险，并行化机会也更少。理想情况下，Job 中只应在需要最新值时读取 Transform 数据，并且每帧最多写入一次 Transform。考虑专用的 TransformAccessArray Job 仅用于提取和输出 Transform 值，并使用临时的 NativeArray 存储中间数据。这种策略可以显著提升 Job 的并行性。\n7. 注意 Transform 访问模式以避免阻塞 这条建议可能是最难诊断和实施的，但影响可能非常明显。主线程通常是帧的critical path，因此了解 TransformAccessArray Job 访问了哪些 Transform 层级结构，以及主线程何时访问这些层级结构，是非常重要的。如前面的场景所示，最坏的情况是：主线程在调度了一个访问某 Transform 层级结构的 Job 后不久，又试图访问同一个层级结构，从而导致阻塞。具体的解决方案因项目而异，但一个通用策略是：仔细规划主线程在帧中访问 Transform 的时机，并调整 Transform 层级结构以更好地匹配 Job 的执行图。\nUnity Job System性能优化愿望清单 在撰写本文的过程中，我发现了一些 Unity 的限制，我认为这些限制可以在不更改或极少更改 API 的情况下得到改进。如果实现，这些改进可以在一些常见场景中为用户带来性能提升。如果有 Unity Job System 的工程师看到，欢迎交流！\n1. 允许主线程与 Job 并行只读访问 Transform 层级结构 我相信 Unity 应该允许主线程与 Job 同时只读访问同一个 Transform 层级结构。我确信目前不这么做是有原因的，但在并行编程中，只读访问共享资源是非常常见的模式，而且在大多数环境中，只读访问比读写访问更高效。理论上，Unity 可以在不更改 API 的情况下实现这一改进，因为只读语义已经存在。\n2. 打破 TransformAccessArray Job 对 Transform 层级结构的“整体”依赖 目前，一个 Job 必须等待所有之前访问过任何一个它所依赖的 Transform 层级结构的 Job 完成后才能开始。\n两个共享 Transform 层级结构的 Job\n在上图中，Job A 访问了一个 Transform 层级结构，Job B 访问了同一个层级结构以及其他几个。由于这一个层级结构的重叠，Job B 必须等 Job A 完成后才能开始，即使 Job A 并不是 Job B 的显式依赖。\n当然，在这个简单的例子中，可以将 Job B 拆成两部分：一部分受 Job A 阻塞，访问共同的层级结构；另一部分不受阻塞，访问其余层级结构。但在复杂场景中，这种做法很快就会变得难以管理。\nUnity 可以为用户无缝处理这种复杂性。由于 TransformAccessArray 实例已经按 Transform 根节点对 Transform 进行了分组，Unity 应该可以在后台将 Job 拆分成多个部分，每个部分对应一个 Transform 层级结构。每个部分可以在其对应的层级结构 fence 解除阻塞后立即开始执行。虽然这可能会带来一些关于任务批次大小的微妙差异，但潜在的性能提升是值得的。\n3. 缓存 localToWorldMatrix 的计算结果 我还没有深入研究具体的实现，但也许 Transform 层级结构应该缓存最近一次计算的 localToWorldMatrix 值，这是所有其他世界空间 Transform 值的基础。在大多数访问世界空间值的 TransformAccessArray Job 中，这个值可能会被反复计算，而且随着层级结构加深，成本会越来越高。\n结论 并行编程总是复杂的，而 Unity 又增加了一些“曲折”，了解这些细节对于榨干 Job System 的性能至关重要。本文中的不同场景模拟了你在实际游戏中可能遇到的情况，尽管真实项目中的复杂性更高。\n有趣的是，我的研究还揭示了 Job System 中一个潜在的死锁问题，我认为这个问题在实际项目中可能相当普遍。我工作的《Toca Boca Days》游戏很可能就遇到了这个问题。希望我的 Bug 报告能成为 Unity 的一个修复，惠及整个 Unity 社区。\n最后，再次强调：在你进行复杂的优化之前，请先分析你的游戏，找出真正的性能瓶颈！\nThanks to Fredrik Bergljung for your support and to an anonymous tech reviewer!\n","ref":"/blog/readingnotes/unitystransformaccessarray/"},{"title":"Unity DOTS(Jobs)","date":"","description":"Unity DOTS(Jobs)","body":"详细介绍Unity DOTS-Jobs的入门和技巧\n安装 Unity版本：2020.3 Jobs版本：0.50.1 地址：Unity Jobs Package 打开Package Manager，使用Add package from git URL添加com.unity.jobs。\n这样就能把想相关依赖包也加入。\nNativeContainer 简单来说，Unity针对Jobs和Entities定义了一种可以在C#上安全访问原生内存的数据类型。它包含了一个指向非托管分配内存的指针，在Jobs环境下，Job可以通过NativeContainer安全的访问主线程共享（不是拷贝数据）的数据，提高了访问效率。\n注意：NativeContainer虽然包含了指向非托管分配内存的指针，但它自己是托管对象。\nNativeContainer实际上是符合NativeContainer安全的数据结构统称，包括以下几种：\n名称 介绍 NativeArray Array的NativeContainer形式 NativeList List的NativeContainer形式 NativeHashMap HashMap的NativeContainer形式 NativeMultiHashMap 一对多HashMap的NativeContainer形式 NativeQueue Queue的NativeContainer形式 分配器（Allocator） 当创建一个NativeContainer时，你必须指定你需要的内存分配类型。分配的类型由jobs运行的时间来决定。这种情况下你可以在每一种情况下使分配器达到可能的最好性能。\n这里对于NativeContainer的内存分配有三个分配器类型。当你初始化你的NativeContainer时你需要指定一个合适的分配器。\nAllocator.Temp：是最快的分配类型。它适用于分配一个生命周期只有一帧或更短时间的操作。你不应当把一个分配器为Temp类型分配的NativeContainer传递给jobs使用。你同时需要在函数返回之前调用Dispose方法(例如MonoBehaviour.Update，或者其他从原生到托管代码的调用) Allocator.TempJob：是速度介乎与Temp与Persistent之间的分配类型。这是一个生命周期为四帧的内存分配而且它是线程安全的。如果你在四帧之内没有调用Dispose，控制台会打印一个由原生代码生成的警告信息。绝大部分小jobs使用这种类型的NativeContainer分配器。 Allocator.Persistent：是最慢的分配类型，但它可以持续存在到你需要的时间，如果必要的话可以贯穿应用程序的整个生命周期。它是直接调用malloc的一个封装。长时间的jobs可以使用这种分配类型。当性能比较紧张的时候你不应当使用Persistent。 安全性系统 安全性系统内置于所有NativeContainer类型，它会追踪所有关于任何NaiveContainer的读写。\n注意：所有安全性检查只在Unity编辑器下可用。\n安全性系统是由DisposeSentinel和AtomicSafetyHandle组成：\nDisposeSentinel：内存泄漏检测，不过只会在内存泄漏的发生很久之后触发错误。\nAtomicSafetyHandle：原子安全检测，对写入冲突进行检查，如果两个及以上的Jobs同时对同一个NaiveContainer写入数据，就会抛出异常。需要等上一个job写入完成后，下一个才能安全写入。读取则不受限制，可以并行读取。\n默认情况下，job声明了NaiveContainer之后就拥有读写权限，这样会降低读写访问性能。如果job不用写入操作可以添加[ReadOnly]特性。\n[ReadOnly] public NativeArray\u0026lt;int\u0026gt; input; 注意：这边没有针对从一个job中访问静态数据的保护。访问静态数据可以绕过所有的安全性系统并可能导致Unity奔溃。\n自定义NativeContainer 根据官方案例做了一些调整（修改/屏蔽了2020.3缺少的API接口）：\nUnsafeUtility.MallocTracked改为UnsafeUtility.Malloc，去掉最后一个参数。 UnsafeUtility.FreeTracked改为UnsafeUtility.Free，去掉最后一个参数。 屏蔽UnsafeUtility.IsNativeContainerType\u0026lt;T\u0026gt;调用 屏蔽AtomicSafetyHandle.SetNestedContainer调用 首先是定义NativeContainer结构，有以下条件：\nstruct类型 有unsafe标签 需要标记[NativeContainer]特性，告诉JobSystem这是拥有AtomicSafetyHandle的容器 由于需要手动管理、释放内存，因此需要实现IDisposable接口 [NativeContainer] public unsafe struct NativeAppendOnlyList\u0026lt;T\u0026gt; : IDisposable where T : unmanaged { //... } 定义基础属性：\nm_Buffer：容器的内存块指针，使用[NativeDisableUnsafePtrRestriction]特性解除了原生指针的限制 m_AllocatorLabel：分配器 m_Safety：原子安全句柄 s_staticSafetyId：原子安全句柄的ID [NativeDisableUnsafePtrRestriction] internal void* m_Buffer; internal int m_Length; internal Allocator m_AllocatorLabel; #if ENABLE_UNITY_COLLECTIONS_CHECKS internal AtomicSafetyHandle m_Safety; internal static readonly int s_staticSafetyId = AtomicSafetyHandle.NewStaticSafetyId\u0026lt;NativeAppendOnlyList\u0026lt;T\u0026gt;\u0026gt;(); #endif 申请内存/释放内存：\nNativeContainer由于是采用非托管内存来管理数据，所以需要使用UnsafeUtility.Malloc和UnsafeUtility.Free来分配和释放。\n为了确保内存块大小正确，还需要使用UnsafeUtility.SizeOf\u0026lt;T\u0026gt;()来计算类型的内存大小。\n//申请内存 int totalSize = UnsafeUtility.SizeOf\u0026lt;T\u0026gt;() * m_Length; m_Buffer = UnsafeUtility.Malloc(totalSize, UnsafeUtility.AlignOf\u0026lt;T\u0026gt;(), m_AllocatorLabel); //释放内存 UnsafeUtility.Free(m_Buffer, m_AllocatorLabel); //写入元素到指针的偏移位置 UnsafeUtility.WriteArrayElement(m_Buffer, m_Length++, value); 原子安全句柄操作：\n注意：涉及到AtomicSafetyHandle的需要包含在ENABLE_UNITY_COLLECTIONS_CHECKS里。\n#if ENABLE_UNITY_COLLECTIONS_CHECKS //创建原子安全句柄 m_Safety = AtomicSafetyHandle.Create(); //设置ID AtomicSafetyHandle.SetStaticSafetyId(ref m_Safety, s_staticSafetyId); //每次写入时，自动升级版本号 AtomicSafetyHandle.SetBumpSecondaryVersionOnScheduleWrite(m_Safety, true); //检查读取权限 AtomicSafetyHandle.CheckReadAndThrow(m_Safety) //检查写入权限 AtomicSafetyHandle.CheckWriteAndThrow(m_Safety); //检查解除释放权限 AtomicSafetyHandle.CheckDeallocateAndThrow(m_Safety); //释放句柄 AtomicSafetyHandle.Release(m_Safety); #endif Jobs 以上图片描述了整个Jobs的调度流程。\nJob 常用的接口如下：\n接口名称 作业数 线程 跨批次写入权限 说明 IJob 单个 单个Worker线程 所有数据 与其他Job和主线程并行的单个作业 IJobParallelFor 多个 多个线程（Main/Worker）并行 当前index 将任务拆分成多个Job，在多个线程并行执行 IJobFor 多个 Run(Main线程)、\nSchedule(单个Worker线程)\n多个工作线程同时 当前index 可以理解为执行模式更灵活的IJobParallelFor IJobParallelForBatch 多个 多个线程（Main/Worker）并行 [index, index + count) 可以理解为数据访问更灵活的IJobParallelFor。\n每个Job可以处理多个索引的数据，而不只是当前索引的数据。 IJobParallelForDefer 多个 多个线程（Main/Worker）并行 当前index 可以理解为遍历次数能够动态调整的IJobParallelFor。\n可以传入NativeList，直到真正调度时才决定长度。 IJobParallelForFilter 多个 单个线程（Main/Worker） 当前index 用于过滤数据后对List元素进行删除或者添加。(未来改名为IJobFilter) IJobParallelForTransform 多个 多个线程（Main/Worker）并行 当前index 可以在Job访问Transform。 创建Job有以下几点要注意的：\nJob一定是struct Job里使用的成员变量只能为Blittable类型或NativeContainer类型 使用的成员变量不能是引用对象（托管堆内存） 不能调用静态对象 只能在主线程调用的Unity接口无法使用 Jobs为了解决在多线程出现的数据竞争条件，会为每个Job发送一份数它需要操作的数据副本，而不是主线程中数据的引用，这有效隔离了数据。\n由于复制数据是在原生环境操作，所以Job只能访问Blittable类型或NativeContainer类型。前者在托管环境和非托管环境传递不需要转换，而后者则直接使用UnsafeUtility.Malloc申请非托管内存。\nIJob 根据示例，可以实现IJob接口，然后实现Execute。\n[BurstCompile] public struct AddJob : IJob { public float number; public NativeArray\u0026lt;float\u0026gt; result; public void Execute() { for (var i = 0; i \u0026lt; position.Length; i++) { result[i] = number + i; } } } Schedule 调度一个Job，此时会把Job放入（Job）队列，然后JobSystem会在这个Job的依赖（前置）Job完成之后（如果有依赖项）开始调用这个Job。\n注意：只能在主线程调用Schedule。\nNativeArray\u0026lt;float\u0026gt; result = new NativeArray\u0026lt;float\u0026gt;(10, Allocator.TempJob); AddJob job = new AddJob(); job.number = 100; job.result = result; // 对Job进行调度，然后拿到调度的句柄 JobHandle handle = jobData.Schedule(); // 等待Job完成 handle.Complete(); Debug.Log(result[0]); //Log: 100 // 需要在最后手动释放NativeContainer result.Dispose(); JobHandle 当你调用Schedule方法时会返回一个JobHandle。它可以用来阻塞主线程等待完成，或者用来作为其他Job的前置依赖。\n下面代码就展示了JobHandle的几种用法：\n// 调度Job a JobHandle aJobHandle = aJob.Schedule(); // 调度Job b，但需要依赖Job a（等待Job a完成） JobHandle bJobHandle = bJob.Schedule(a); JobHandle cJobHandle = cJob.Schedule(); // 可以将多个JobHandle合并成单个，然后作为其他Job的前置依赖（需要等待多个Job完成） JobHandle bcJobHandle = JobHandle.CombineDependencies(bJobHandle, cJobHandle); JobHandle dJobHandle = dJob.Schedule(bcJobHandle); // 阻塞主线程，等待完成 dJobHandle.Complete(); P.S. Job在调度时不会立刻开始执行，如果需要在主线程等待作业，并需要访问作业所使用的NativeContainer数据，可以调用Complete方法刷新内存缓存中的Job并开始执行，才可以确保后续逻辑运行时Job已经执行完成，才能在主线程安全的访问Job中的NativeContainer。1\nIJobParallelFor IJobParallelFor是并行Job的其中一个实现接口（后面版本还有IJobParallelForTransform等），它主要是把相同任务拆分成多个Job来同时执行。\n在讲解IJobParallelFor前，首先要根据下图理解一些概念：\nExecute(n)：单个可执行的任务 Batch：多个任务（Execute(n)）集合 Batches：多个Batch的集合 Native Job：放置在Job Queue的原生作业，里面包含了一个Batches 根据官方图示，IJobParallelFor的执行流程如下：\nMain Thread： 在主线程创建的并行Job 根据ParallelFor Job的数据源长度，创建可执行的任务（Execute(n)），放入Data Source。 C# Job System 将任务划分成多个Batch块，每个Batch有batchSize（innerloopBatchCount）个任务。 Job Queue 创建Native Job，放入Batch块 将Native Job放入到Job Queue Native Job System 从Job Queue弹出Native Job，放入工作线程并执行其Batches 存储结果到Native内存（可以理解为Native Container） 在调度IJobParallelFor时，需要设定数据源长度，这可以告诉Job System需要创建多少个任务（Execute方法），因为Job System无法知道哪个NativeContainer是数据源，也不知道数据源长度和任务数的关系。\n举个例子就是：NativeArray每三个数据表示为一个三位坐标x、y、z，需要一起处理，那么创建的任务数就是NativeArray.Length/3，并不是NativeArray.Length。\n这里有一个限制，只要是[WriteOnly]的NativeArray/NativeList，写入index以外位置都会抛出异常。而[ReadOnly]没有这个限制。如果需要跨批次写入可以使用IJobParallelForBatch。\n在调度时还需要设置batchSize（innerloopBatchCount），这是告诉Job System单个batch的任务颗粒度是多少（也就是有多少个Execute方法）。由于一个Native Job在执行完之后会窃取其他的Native Job的剩余批次（一次只能窃取剩余批次的一半，以确保缓存局部性2）。\nbatchSize可以控制Job的数量，以及线程之间重新分配工作的细化程度。值设置的较小（例如1）可以使线程之间的工作分布更均匀，但也会带来一些开销，所以需要根据实际情况来设置这个值，如果单个任务较为简单，可以将值设置较大，如果单个任务较为复杂耗时，可以将值设置更小。\n//调度一个IJobParallelFor，将array作为数据源，将array.Length作为数据源长度。batchSize设置为64 parallelForJob.Schedule(array.Length, 64); IJobFor IJobFor可以理解为执行模式更灵活的IJobParallelFor。他提供了三种调用方法：\nRun：直接在主线程顺序执行。还是会根据数据源长度来创建多个任务（Execute） Schedule：可以在单个工作线程（或主线程）顺序执行。如果调用JobHandle.Complete方法会直接在主线程执行。 ScheduleParallel：根据官网描述跟IJobParallelFor.Schedule一样。 看起来IJobFor的用途并不广泛，所以篇章较少。\nIJobParallelForBatch IJobParallelForBatch是数据访问更灵活的IJobParallelFor。IJobParallelFor是无法在[WriteOnly]的NativeArray/NativeList中写入Index以外的数据。而有些情况下，需要写入到其他位置。\nIJobParallelForBatch可以把数据以n为一组分配到一个Job，然后这个Job就可以处理[index, index + n]之间的数据。\n相当于如下差异：\n//IJobParallelFor void Schedule(int arrayLength, int innerloopBatchCount) { for (int i = 0; i \u0026lt; arrayLength; i++) { Job.Execute(i); } } ​ //IJobParallelForBatch void ScheduleBatch(int arrayLength, int innerloopBatchCount) { for (int i = 0; i \u0026lt; arrayLength; i+=innerloopBatchCount) { Job.Execute(i, innerloopBatchCount); } } IJobParallelForBatch在后续版本迁移到com.unity.collections里。\nIJobParallelForDefer IJobParallelForDefer跟IJobParallelFor的不同是，可以传入NativeList或长度的指针作为调度的参数，可以在真正调度时才确定迭代总次数。\n这样的好处是，如果job是在中间（多线程下Schedule后不一定立刻调度）开始调度，他的长度就可以依赖前置的Job来决定。\n而IJobParallelFor需要在一开始Schedule就确定了长度，是没法这样动态处理的。\n// 数据动态变化（可能是上一个Jobs决定的） NativeList\u0026lt;Instance\u0026gt; instances; // instances.Length在真正调度才确定 job.Schedule(instances, 64); // 另外一种方式传入长度指针 int* countRef = \u0026amp;count // 调度时传入长度指针 job.Schedule(countRef, 64); // 之后更改长度 count = 128; 传入NativeList应该是比较常用的用法了，NativeList可能是基于前置IJobParallelForFilter输出的列表。\n而传入指针的方式，笔者想象到实际的使用场景是把指针传入到前置job里面来修改，但应该不太常见。\nIJobParallelForDefer在后续版本迁移到com.unity.collections里。\nIJobParallelForFilter IJobParallelForFilter用于过滤数据后对NativeList元素进行删除或者添加。他提供了两个常用方法，分别是：\nScheduleFilter：传入NativeList\u0026lt;T\u0026gt;，对NativeList进行迭代，判断NativeList\u0026lt;T\u0026gt;[index]中的数据是否符合要求，不符合则进行删除。 ScheduleAppend：传入NativeList\u0026lt;T\u0026gt;和总的迭代次数，判断对应索引的数据，然后对符合的索引进行添加。 void Filter() { NativeArray\u0026lt;float\u0026gt; source = new NativeArray\u0026lt;float\u0026gt;(count, Allocator.TempJob); NativeList\u0026lt;int\u0026gt; filters = new NativeList\u0026lt;int\u0026gt;(count, Allocator.TempJob); NativeList\u0026lt;int\u0026gt; appends = new NativeList\u0026lt;int\u0026gt;(0, Allocator.TempJob); for (int i = 0; i \u0026lt; count; i++) { source[i] = i + i / 10.0f; filters.Add(i * 2); } if (filterOrAppend) { var filterJob = new FilterJob() { }; var filterHandle = filterJob.ScheduleFilter(filters, 64); filterHandle.Complete(); Debug.Log(filters.Length); for (int i = 0; i \u0026lt; filters.Length; i++) { Debug.Log(filters[i]); } } else { var appendJob = new AppendJob() { source = source }; var appendHandle = appendJob.ScheduleAppend(appends, count, 64); appendHandle.Complete(); Debug.Log(appends.Length); for (int i = 0; i \u0026lt; appends.Length; i++) { Debug.Log(appends[i]); } } source.Dispose(); filters.Dispose(); appends.Dispose(); } [BurstCompile] public struct FilterJob : IJobParallelForFilter { //在ScheduleFilter中，传入的index实际上NativeList\u0026lt;T\u0026gt;的值。这里是数据还是索引就取决于怎么使用。 public bool Execute(int index) { if(index \u0026gt; 10) { return true; } return false; } } [BurstCompile] public struct AppendJob : IJobParallelForFilter { [ReadOnly] public NativeArray\u0026lt;float\u0026gt; source; public bool Execute(int index) { if(source[index] \u0026gt; 5) { return true; } return false; } } ScheduleFilter迭代的是NativeList中的元素，并不是根据NativeList长度来迭代。而迭代的元素是数据还是索引就取决于怎么使用，在例子里面就是数据。\nScheduleAppend的NativeList则不一样，添加的只能是迭代索引值，因为无法确认添加的内容是什么类型。\nScheduleAppend时的NativeList长度可以为0，这样可以减少内存占用，但随之带来的是在Job中扩容，性能会有一定影响。\n另外要注意的：IJobParallelForFilter虽然有ParallelFor字样，实际上它调用的是JobsUtility.Schedule，其实是单线程执行，因此最新版本将IJobParallelForFilter改名为IJobFilter\nJobs进阶 展示Jobs的一些进阶用法。\nNativeList\u0026lt;T\u0026gt;.AsParallelWriter() 上述讲过的IJobParallelForFilter这个接口，它可以过滤数据，然后对符合的数据进行添加或者删除。实际上也可以使用NativeList\u0026lt;T\u0026gt;.ParallelWriter()来满足添加元素的需求。\nParallelWriter提供了更自由的并行写入的方法，相对IJobParallelForFilter添加时只能添加索引，ParallelWriter能够添加任意内容。\nAsParallelWriter()返回NativeList\u0026lt;T\u0026gt;.ParallelWriter类型实例，然后我们将这个类传入到Job，然后在Job中使用ParallelWriter.AddNoResize添加元素。\nNativeList\u0026lt;int\u0026gt; filterList = new NativeList\u0026lt;int\u0026gt;(expectedMax, Allocator.TempJob); var filterJob = new FilterJob{ src = data, outIndex = filterList.AsParallelWriter() }; filterJob.Schedule(data.Length, 64).Complete(); [BurstCompile] struct FilterJob : IJobParallelFor { [ReadOnly] public NativeArray\u0026lt;float\u0026gt; src; public NativeList\u0026lt;int\u0026gt;.ParallelWriter outIndex; // 并发写索引列表 public void Execute(int i) { if (src[i] \u0026gt; 0.5f) // 任意过滤条件 { outIndex.AddNoResize(i); } } } AddNoResize()可以原子地把元素写到当前Length位置，然后把Length++。\n注意：AddNoResize()不会进行扩容，因此需要在使用前预分配足够大的容量。\n性能相对比Add要低，因为涉及到原子锁。\nNativeList\u0026lt;T\u0026gt;.AsDeferredJobArray() 上述讲过的IJobParallelForDefer这个接口，它可以在正式调度时才确定长度。而Unity官方也提供了另外一种方式实现这个功能，那就是IJob + NativeList\u0026lt;T\u0026gt;.AsDeferredJobArray()。（当然，这方案其实无法并行）\nAsDeferredJobArray()主要作用是分配一个NativeArray\u0026lt;T\u0026gt;实例，将数据指针指向原NativeList\u0026lt;T\u0026gt;的数据。这样在IJob.Schedule()时，可以传入这个NativeArray，在实际调度时，才会确定具体长度。\nNativeList\u0026lt;int\u0026gt; filter = new NativeList\u0026lt;int\u0026gt;(maxCount, Allocator.TempJob); //前面的Job对NativeList\u0026lt;T\u0026gt;进行数据过滤，例如IJobParallelForFilter的案例。 //... //使用 var job = new SumJob{ indices = filter.AsDeferredJobArray(), data = data, sum = output }; job.Schedule(); [BurstCompile] public struct Sum : IJob { [ReadOnly] public NativeArray\u0026lt;int\u0026gt; indices; public NativeArray\u0026lt;int\u0026gt; data; public void Execute() { sum[0] = 0; for (int i = 0; i \u0026lt; indices.Length; i++) { sum[0] += data[indices[i]]; } } } 由于返回的NativeArray\u0026lt;T\u0026gt;并不是NativeList\u0026lt;T\u0026gt;的数据副本，因此不会出现多份内存，也不会增加拷贝的消耗。\n特别注意的是：返回的NativeArray\u0026lt;T\u0026gt;是别名，并不拥有数据内存，无需调用Dispose；等原NativeList\u0026lt;T\u0026gt;销毁即可。\nNativeList\u0026lt;T\u0026gt;.AsParallelReader() AsParallelReader()可以快速的拿到NativeList\u0026lt;T\u0026gt;的一个只读、无安全检查的只读NativeArray\u0026lt;T\u0026gt;，跟AsDeferredJobArray()都不会产生拷贝或额外的内存分配。\n它的长度在获取的那一刻就已经固定了，这点跟AsDeferredJobArray()有较大的差别，然后AsDeferredJobArray()可以写入，但AsParallelReader()是只读。\n虽然这个只读NativeArray\u0026lt;T\u0026gt;不能写入，但原NativeList\u0026lt;T\u0026gt;修改数据（原长度部分的数据）时，由于是只读视图，所以仍然会影响到NativeArray\u0026lt;T\u0026gt;的数据。\n特别注意的是：返回的NativeArray\u0026lt;T\u0026gt;是只读视图，并不拥有数据内存，无需调用Dispose；等原NativeList\u0026lt;T\u0026gt;销毁即可。\nAsParallelReader()在后续版本已更名为AsReadOnly()。\n内存管理 StructLayout StructLayout是一个控制数据字段物理内存布局的特性，他可以添加到Class或者Struct中。\nLayoutKind：指定如何排列类或结构。使用LayoutKind的枚举值。 Pack：控制类或结构的数据字段在内存中的对齐方式。 Size：指示类或结构的绝对大小。 CharSet：指示在默认情况下是否应将类中的字符串数据字段作为LPWSTR或LPSTR进行封送处理。 先来说一下LayoutKind：\nAuto：由运行库自动决定对象在内存中的布局方式，因为这是运行库内部规则根据不同运行环境决定的字段顺序和对齐方式，无法确保在非托管代码中的内存布局一致，因此对象无法传给托管代码以外使用。 Sequential：Class或者Struct中的字段会按其（声明）顺序在内存排列，编译器插入填充字节满足对齐要求。 Sequential对于blittable类型，托管代码和非托管代码的内存布局一致，可以互相传递。 Sequential对于非blittable类型，托管代码不受影响，运行时会自动插入填充字节或调整字段顺序。而非托管代码则会按照声明顺序排序。与托管代码的内存布局可能不同，因此不能直接传递。 Explicit：显式指定字段偏移量。 Explicit对于blittable类型，托管代码和非托管代码的内存布局一致，都是根据字段偏移量来确定内存布局，可以互相传递。 Explicit对于非blittable类型，托管代码不受影响，运行时会自动插入填充字节或调整字段顺序。而非托管代码则会按照字段偏移量来确定内存布局。与托管代码的内存布局可能不同，因此不能直接传递。 默认值：\nStruct默认为Sequential，但拥有引用类型字段时，默认会变成LayoutKind.Auto。 Class默认为LayoutKind.Auto。 Blittable 上文提及到Job的成员变量需要使用Blittable类型或者NativeContainer类型，这里说的Blittable是指那些在托管代码和非托管代码中为相同内存布局的类型总称，特点就是托管和非托管互相传递时不需要进行特殊转换。\n常见的Blittable： 类型名 字段大小 System.Byte 1 System.SByte 1 System.Int16 2 System.UInt16 2 System.Int32 4 System.UInt32 4 System.Single 4 System.Int64 8 System.UInt64 8 System.Double 8 System.IntPtr 4(32位) 或 8(64位) System.UIntPtr 4(32位) 或 8(64位) 常见的Blittable复杂类型：\nBlittable基元类型的一维数组，如整数数组。但是，包含基元类型一维数组字段的类型并不是Blittable。 所有字段为Blittable的类型，并且使用LayoutKind.Sequential或LayoutKind.Explicit布局的Struct也是Blittable 不是Blittable的情况：\nbool这个最容易理解错，true在不同平台可能会有不同值，对应的字节数可能是1、2或者4。 char涉及不同的编码。 对象引用不是Blittable类型，这包括本身是Blittable对象的引用数组。 有疑问的情况：\nint[][]使用UnsafeUtility.IsBlittable判定为Blittable，这个跟官网描述不一致。 非Blittable的struct对象，其数组也判定为Blittable，这个也能笔者疑惑。 注意：有疑问的情况列举的是基于Unity的UnsafeUtility.IsBlittable接口返回结果，实际上.Net的官网描述跟Unity判定笔者是觉得有出入。\n原生内存分配 上文分别提到NativeContainer，分别使用了UnsafeUtility.SizeOf和UnsafeUtility.AlignOf两个接口，这两个接口都是分配原生内存时需要使用的接口。\nUnsafeUtility.SizeOf是返回指定结构类型的总字节数，其中包括因为字段对齐而填充的字节。 UnsafeUtility.AlignOf是指定结构类型在内存中所需的最小对齐大小。在分配内存时需要把结果告诉内存分配，从而确保数据结构正确对齐，提高访问速度。 SizeOf和AlignOf都跟StructLayout相关，AlignOf实际上是根据结构体最大字段字节和StructLayout.Pack取最小值得出来的，表示这个结构体的最小对齐大小。而SizeOf则是根据结构体的对齐内存和填充内字节后的实际字节数得到的。3 4\nJobSystemJobDependencies, https://docs.unity3d.com/cn/2020.3/Manual/JobSystemJobDependencies.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nWhy does cache locality matter for array performance?, https://stackoverflow.com/questions/12065774/why-does-cache-locality-matter-for-array-performance\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n理解.NET结构体字段的内存布局, https://www.cnblogs.com/eventhorizon/p/18913041\u0026#160;\u0026#x21a9;\u0026#xfe0e;\naligned_malloc实现内存对齐, https://blog.csdn.net/jin739738709/article/details/122992753\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","ref":"/blog/unity3d/dotsjobs/"},{"title":"【阅读笔记】HowToRTS","date":"","description":"阅读“HowToRTS”教程的研究笔记","body":"阅读“flow-field-pathfinding”源码的研究笔记\n简介 教程地址：https://howtorts.github.io/\n常用结构 Vector2 构造函数和静态属性\n名称 类型 作用 Vector2(x, y) 构造函数 创建一个二维向量对象，包含x和y坐标 Vector2.zero 静态属性 预定义的零向量 (0, 0) Vector2.one 静态属性 预定义的单位向量 (1, 1) Vector2实例方法\n方法名 参数 返回值 作用 length() 无 Number 计算向量的长度（模长），等于到原点的距离 distanceTo(target) Vector2 Number 计算当前向量到目标向量的欧几里得距离 normalize() 无 Vector2 返回当前向量的单位向量（方向相同，长度为1） round() 无 Vector2 返回坐标四舍五入后的新向量 floor() 无 Vector2 返回坐标向下取整后的新向量 minus(other) Vector2 Vector2 向量减法，返回两向量相减的结果 plus(other) Vector2 Vector2 向量加法，返回两向量相加的结果 mul(scalar) Number Vector2 向量数乘，返回向量与标量相乘的结果 div(scalar) Number Vector2 向量除法，返回向量除以标量的结果 angle() 无 Number 返回向量的角度（以度为单位，相对于Y轴正方向） 工厂函数\n函数名 参数 返回值 作用 vector2(x, y) Array/Vector2 Vector2 工厂方法，可接受数组或Vector2对象，返回Vector2实例 相关辅助类\n类名 构造参数 主要方法 作用 LineSegment start, end interpolatedPoint(percent) 表示线段，可进行插值计算 LineString points数组 无 表示由多个点组成的折线，包含多个线段 注意：所有返回Vector2的方法都会创建新的向量对象，不会修改原向量（不可变性设计）。\nAgent 构造函数\n名称 参数 作用 Agent(pos) pos (Vector2) 创建一个智能体对象，设置初始位置 Agent属性\n属性名 类型 默认值 作用 position Vector2 构造参数pos 智能体当前位置坐标 rotation Number 0 智能体当前旋转角度 velocity Vector2 Vector2.zero 智能体当前速度向量 maxForce Number 5 最大加速度（这里假设单位质量为1，因此用力表示） maxSpeed Number 4 最大速度限制（网格单位/秒） follow a path 教程\n源码\n这个用例比较简单，主要是讲述角色沿着固定路径移动。\n//game tick //敌人移动 for (var i = enemies.length - 1; i \u0026gt;= 0; i--) { var e = enemies[i]; var distanceToMove = dt * e.speed; // 计算在当前时间间隔内敌人应移动的距离 var vectorToTarget = path[e.pathIndex].minus(e.position); // 计算到下一个路径点的向量 var distanceToTarget = vectorToTarget.length(); // 计算到下一个路径点的距离 // 如果敌人在当前时间间隔内可以到达下一个路径点 if (distanceToTarget \u0026lt; distanceToMove) { e.position = path[e.pathIndex]; // 将敌人移动到下一个路径点 e.pathIndex++; // 更新路径索引 // 如果敌人到达路径终点 if (e.pathIndex == path.length) { enemies.splice(i, 1); // 从敌人数组中移除该敌人 continue; } // 重新计算到下一个路径点的移动距离和向量 distanceToMove -= distanceToTarget; vectorToTarget = path[e.pathIndex].minus(e.position); distanceToTarget = vectorToTarget.length(); } // 更新敌人的位置和旋转角度 e.position = e.position.plus(vectorToTarget.normalize().mul(distanceToMove)); e.rotation = vectorToTarget.angle(); } Generating a path with Dijkstra 教程\n源码\n这个教程主要讲述如何使用Dijkstra生成路径：\n先使用广度优先搜索（BFS）来生成Dijkstra网格 然后根据Dijkstra从起点开始生成移动路径 最后再使用上一篇文章的路径移动方案来控制敌人移动 生成Dijkstra网格:\n将所有网格的权重改为空，表示未访问。 再将所有塔的网格权重改为Number最大值，表示为不可达。 将终点权重设置为0，然后放入到待访问列表。 每次从待访问列表里拿出节点（教程用了列表，BFS常见还是用队列比较好）。 遍历节点的四个方向邻居。 如果邻居节点未访问过，则设置其权重值为当前节点权重+1，并将邻居节点放入待访问列表。 重复执行4、5、6，直到待访问列表为空。 权重值就是节点到终点的曼哈顿距离。\n最后可得到整个网格所有节点到终点的距离（权重）。以下为教程源码：\nfunction generateDijkstraGrid() { // 生成一个空网格，所有位置的权重设置为 null（表示未访问） dijkstraGrid = new Array(gridWidth); for (var x = 0; x \u0026lt; gridWidth; x++) { var arr = new Array(gridHeight); for (var y = 0; y \u0026lt; gridHeight; y++) { arr[y] = null; } dijkstraGrid[x] = arr; } // 将塔的位置设置为权重 MAXINT（表示无法通过） for (var i = 0; i \u0026lt; towers.length; i++) { var t = towers[i]; dijkstraGrid[t.x][t.y] = Number.MAX_VALUE; } // 从终点开始进行洪水填充 pathEnd.distance = 0; dijkstraGrid[pathEnd.x][pathEnd.y] = 0; var toVisit = [pathEnd]; // 待访问节点队列 // 遍历待访问节点 for (i = 0; i \u0026lt; toVisit.length; i++) { var neighbours = neighboursOf(toVisit[i]); // 获取当前节点的邻居 // 遍历邻居节点 for (var j = 0; j \u0026lt; neighbours.length; j++) { var n = neighbours[j]; // 如果邻居节点未访问过 if (dijkstraGrid[n.x][n.y] === null) { n.distance = toVisit[i].distance + 1; // 设置权重 dijkstraGrid[n.x][n.y] = n.distance; toVisit.push(n); // 加入待访问队列 } } } } 根据Dijkstra生成移动路径：\n判断起点是否为未访问或者不可达，如果是则直接返回。 将起点放入到路径列表中，并将起点作为当前节点。 获取当前节点的四个方向邻居节点。 然后将最小权重的邻居节点放入路径列表中，并且作为下一个待访问节点。 重复步骤3、4，知道当前节点等于终点。 最后可得到起点到终点的移动路径。以下为教程源码：\nwhile (at.x != pathEnd.x || at.y != pathEnd.y) { currentWeight = dijkstraGrid[at.x][at.y]; var neighbours = neighboursOf(at); // 获取当前位置的所有邻居节点 var next = null; // 用于存储下一个要移动到的节点 var nextWeight = currentWeight; // 初始化下一个节点的权重为当前权重 // 遍历所有邻居节点 for (var i = 0; i \u0026lt; neighbours.length; i++) { var neighbour = neighbours[i]; var neighbourWeight = dijkstraGrid[neighbour.x][neighbour.y]; // 如果邻居节点的权重小于当前权重 if (neighbourWeight \u0026lt; nextWeight) { next = neighbour; // 更新下一个节点 nextWeight = neighbourWeight; // 更新下一个节点的权重 } } path.push(next); // 将下一个节点加入路径 at = next; // 更新当前位置为下一个节点 } Steering Behaviours Introduction 教程：Steering Behaviours Introduction\n源码：3-1-steering-behaviours-seek\n参考：The-Next-Vector-Improvements-in\nRTS游戏有以下的特点，单位不会互相穿透，可以避开障碍，并且像一个群体一样移动。因此这里使用到Steering Behaviours（转向行为）\n常见行为：\nSeek（寻找）：向固定点移动 Flee（逃离）：远离固定点 Pursue（追击）：预测实体的未来位置并寻求拦截它 Evade（躲避）：预测实体的未来位置并逃跑避开它 Avoidance（回避）：避免撞到东西 Seek转向行为：\nfunction steeringBehaviourSeek(agent) { // 使用终点减智能体当前坐标，得出指向向量（desired） var desired = destination.minus(agent.position); // 最大速度除以 desired = desired.mul(agent.maxSpeed / desired.length()); // 期望速度 - 当前速度 = 需要改变的“速度差” var force = desired.minus(agent.velocity); // 把速度差转换成实际可施加的力（按最大推力比例缩放） return force.mul(agent.maxForce / agent.maxSpeed); } Seek公式：\n$$ \\begin{aligned} \\vec{d} \u0026= P_{dest} - P_{agent} \\\\\\\\ \\vec{v}_{desired} \u0026= \\frac{\\vec{d}}{|\\vec{d}|} \\cdot v_{max} \\\\\\\\ \\vec{F} \u0026= (\\vec{v}_{desired} - \\vec{v}_{agent}) \\cdot \\frac{F_{max}}{v_{max}} \\\\\\\\ \\end{aligned} $$ 其中\n$P_{dest}$：目标位置 $P_{agent}$：智能体当前位置 $\\vec{d}$：智能体当前位置指向终点的向量。 $v_{max}$：最大允许速度(量) $F_{max}$：最大允许推力(量) 最终返回的 $\\vec{F}$ 就是施加在智能体上的转向力。\n这里的公式与代码有一些差别：变量命名和公式顺序\n首先就是desired，在代码里面是一个变量，但在公式里面分别是指向终点的向量：$\\vec{d}$ 和指向终点的速度：$v_{max}$。\n代码为了优化是先计算$\\frac{v_{max}}{|\\vec{d}|}$，实际上这里是先求$\\vec{d}$单位向量，然后再乘最大速度来求期望速度。\n最后一条公式比较晦涩，因为力除以速度没有任何物理意义。如果加上质量就很清晰了：\n$$ \\vec{F} = \\vec{v}_{desired} - \\vec{v}_{agent} $$ $$ \\begin{aligned} F = ma \\quad a = \\frac{\\Delta v}{\\Delta t} \\\\\\\\ F = m\\frac{\\Delta v}{\\Delta t} \\\\\\\\ \\text{两边同除以} \\Delta v\\quad \\frac{F}{\\Delta v} = \\frac{m}{\\Delta t} \\\\\\\\ \\end{aligned} $$ $$ \\begin{aligned} \\vec{F} \u0026= (\\vec{v}_{desired} - \\vec{v}_{agent}) \\cdot \\frac{F_{max}}{v_{max}} \\\\\\\\ \u0026= (\\vec{v}_{desired} - \\vec{v}_{agent}) \\cdot \\frac{m}{t} \\\\\\\\ \u0026= \\frac{\\vec{v}_{desired} - \\vec{v}_{agent}}{t} \\cdot m \\end{aligned} $$ 这样就可以理解为最大推力使物体达到最大速度所使用的时间，让物体转向到期望速度所需要的推力。\n移动智能体：\n// game tick // 遍历并移动所有智能体（从后向前，便于动态增删） for (var i = agents.length - 1; i \u0026gt;= 0; i--) { var agent = agents[i]; // 计算当前智能体的“寻找”行为力 var seek = steeringBehaviourSeek(agent); // 将力施加到速度上（加速度积分） agent.velocity = agent.velocity.plus(seek.mul(dt)); // 如果速度超过最大速度，则进行限速 var speed = agent.velocity.length(); if (speed \u0026gt; agent.maxSpeed) { agent.velocity = agent.velocity.mul(agent.maxSpeed / speed); } // 根据速度方向更新朝向角度 agent.rotation = agent.velocity.angle(); // 根据当前速度移动位置 agent.position = agent.position.plus(agent.velocity.mul(dt)); } 这里获取到的seek其实就是seek返回的推力，由于忽略了质量（假设为1），因此后续计算直接乘以时间来获得推力方向的速度，最后再叠加到智能体当前速度，然后将最终速度限制在最大速度。\nSteering Behaviours: Flocking 教程：Steering Behaviours: Flocking\n源码：3-2-steering-behaviours-flock\n群集行为是转向行为的一个子集，根据相邻智能体调整\n群集行为：\nSeparation（分离）：远离太过亲近的实体 Cohesion（凝聚）：靠近那些我们靠近但不够近的实体 Alignment（结盟）：改变方向，更加贴近邻居 Separation（分离） 实现代码：\nfunction steeringBehaviourSeparation(agent) { var totalForce = Vector2.zero; var neighboursCount = 0; for (var i = 0; i \u0026lt; agents.length; i++) { var a = agents[i]; if (a != agent) { var distance = agent.position.distanceTo(a.position); if (distance \u0026lt; agent.neighbourRadius \u0026amp;\u0026amp; distance \u0026gt; 0) { //Vector to other agent var pushForce = agent.position.minus(a.position); //Inverse scaled force (bigger the nearer we are) pushForce = pushForce.normalize().mul(1 - (pushForce.length() / agent.neighbourRadius)); totalForce = totalForce.plus(pushForce); neighboursCount++; } } } if (neighboursCount == 0) { return Vector2.zero; } totalForce = totalForce.div(neighboursCount); return totalForce.mul(agent.maxForce); } 遍历所有智能体，然后挑选在生效半径内的邻居，求对应的分离力，最后将分离力求和。\n最后需要除以生效邻居的数量进行平均，最后再乘以力的最大值得到最后的分离力。\nSeparation公式：\n$$ \\begin{aligned} \\vec{d} \u0026= \\vec{p}_{\\text{agent}} - \\vec{p}_{\\text{neighbour}} \\\\ {scale} \u0026= 1 - \\frac{|\\vec{d}|}{r_\\text{neighbour}} \\\\ \\vec{F}_{\\text{push}} \u0026= \\frac{\\vec{d}}{|\\vec{d}|} \\cdot {scale} \\\\ \\vec{F}_{\\text{total}} \u0026= \\vec{F}_{\\text{total}} + \\vec{F}_{\\text{push}} \\end{aligned} $$ 其中：\n$P_{agent}$：智能体当前位置 $P_{neighbour}$：邻居当前位置 $r_{neighbour}$：分离力的生效半径（内） $\\vec{d}$：邻居指向智能体的向量。 $scale$：根据距离计算的缩放量，距离越近，值越大 $F_{push}$：当前邻居所产生的分离力 $F_{total}$：所有邻居（在生效半径内）所产生的分离力 使用智能体和邻居获取分离力的单位方向，然后再根据距离和生效半径求分离力的比例来得到当前邻居产生的分离力。\n后面就是平均分离力，然后再乘以$F_{max}$来得到最终的分离力\n这里单个scale不会超过1的，所有的分离力平均下来也不会超过1，因此最终的分离力不会超过$F_{max}$\nCohesion（凝聚） 实现代码：\nfunction steeringBehaviourCohesion(agent) { //Start with just our position var centerOfMass = agent.position; var neighboursCount = 1; for (var i = 0; i \u0026lt; agents.length; i++) { var a = agents[i]; if (a != agent) { var distance = agent.position.distanceTo(a.position); if (distance \u0026lt; agent.neighbourRadius) { //sum up the position of our neighbours centerOfMass = centerOfMass.plus(a.position); neighboursCount++; } } } if (neighboursCount == 1) { return Vector2.zero; } //Get the average position of ourself and our neighbours centerOfMass = centerOfMass.div(neighboursCount); //seek that position return steeringBehaviourSeek(agent, centerOfMass); } 遍历所有智能体，然后挑选在生效半径内的邻居，跟当前的智能体求一个平均的坐标位置作为聚集点，再使用之前提到的Seek对这个聚集点求吸引力。\nAlignment（结盟） 结盟的运算跟凝聚类似，不过凝聚是智能体靠近邻居的平均位置。而结盟则是让智能体移动一致。\n结盟代码：\nfunction steeringBehaviourAlignment(agent) { var averageHeading = Vector2.zero; var neighboursCount = 0; //for each of our neighbours (including ourself) for (var i = 0; i \u0026lt; agents.length; i++) { var a = agents[i]; var distance = agent.position.distanceTo(a.position); //That are within the max distance and are moving if (distance \u0026lt; agent.neighbourRadius \u0026amp;\u0026amp; a.velocity.length() \u0026gt; 0) { //Sum up our headings averageHeading = averageHeading.plus(a.velocity.normalize()); neighboursCount++; } } if (neighboursCount == 0) { return Vector2.zero; } //Divide to get the average heading averageHeading = averageHeading.div(neighboursCount); //Steer towards that heading var desired = averageHeading.mul(agent.maxSpeed); var force = desired.minus(agent.velocity); return force.mul(agent.maxForce / agent.maxSpeed); } 遍历所有智能体，然后挑选在生效半径内的邻居，将邻居的速度方向想加求平均，得到一个结盟的期望速度方向，然后跟Seek一样，求出一个让智能体趋向于这个速度方向的推力。\n叠加所有力 前面分别做了Seek（寻找）、Separation（分离）、Cohesion（凝聚）、Alignment（结盟）四种作用力的计算，现在需要把它作用到智能体中，计算出最终的速度和位置。\n首先要对作用力的计算和位移分开成两次循环，这是因为位移会影响到作用力的计算，确保每个智能体都是基于一致的情况来做出行为。\n求作用力的代码：\n// game tick // 遍历所有智能体 //Work out our behaviours var seek = steeringBehaviourSeek(agent, destination); var separation = steeringBehaviourSeparation(agent); var cohesion = steeringBehaviourCohesion(agent); var alignment = steeringBehaviourAlignment(agent); //Combine them to come up with a total force to apply agent.forceToApply = seek.plus(separation.mul(2)).plus(cohesion.mul(0.2)).plus(alignment.mul(0.5)); //Cap the force if required if (agent.forceToApply.length() \u0026gt; agent.maxForce) { agent.forceToApply = agent.forceToApply.normalize().mul(agent.maxForce); } 作者并没有把所有的力直接相加，这是因为这些作用力是有优先级的：例如凝聚中靠前面的智能体会有一个凝聚力向后拉扯，有可能导致它或者队伍没法达到最高速度。这种情况下，凝聚力的作用反而产生负面影响，所以作者的做法是对不同作用力加权相加，像凝聚力只需要少量，让队伍不至于分散就行。\n接下来的循环跟之前一样，计算作用力产生的加速度，然后计算出智能体最新的位置、旋转即可。\n优化 作者谈到几个问题和优化的方向：\n凝聚和结盟会让不同终点的单位互相拉扯，导致没法正确最快到达终点。可以只对相似终点的单位进行凝聚和结盟。（作者使用了相似，但这个相似是相对的，离终点越近，相似的阈值应该越低，这个参数并不好调） 重复遍历了智能体多次，时间复杂度较高，可以使用四叉树等空间搜索方法来优化。（这是常见的降时间复杂度方案了） 另外就是从频次入手去减少遍历智能体的耗时，某些转向行为重要性并不是特别高，所以实时性也可以相应降低，可以通过分帧处理来优化，没有计算的帧使用之前缓存。 除了上述所说的，其实还有其他一些优化方向：\n上述的群聚行为，其实都是基于相同范围内的邻居，那其实可以预计算出邻居列表，然后再分发到每个转向行为进行计算。 作者的部分公式实现没有进一步优化，例如不直接用distanceTo计算距离来进行对比，变成计算距离的平方进行对比，这样少开一次根号了，后续也能直接使用向量。 计算分离力时，用的是线性函数。这里换成二次函数一样也能达到目的（分离力会更强，需要在后续适当降低权重）。这样的好处也是减少开根号。 Flow Fields: Line of Sight 教程：Flow Fields: Line of Sight\n源码：9-flow-field-improvements-again\n原文说明 在流场寻路的基础上，增加视野的定义。用于解决“明明直线就可以到达终点，但移动却是曲线”的问题。\n作者的处理方法是通过判断当前的节点是否拥有终点的视野（节点到终点中间没有阻挡）。原文作者的思路如下：\n终点肯定是拥有视野的。 终点的（垂直、水平）直线邻居，也是拥有视野的（非阻挡）。 如果节点跟终点是一条（垂直、水平）直线上的，而更靠近终点的下一个节点有视野，那它也有视野。 这里原文描述的有点绕，简单点就是直线节点和终点之间没有阻挡，则有视野\n如果朝向终点最有影响力的方向节点有视野，并且朝向终点的对角线有视野，那它也有视野 4是原文最难理解的，要说明白，要把两个定义拆开来说：朝向终点最有影响力的方向节点、朝向终点的对角线\n朝向终点最优影响力的方向节点：\n上图的蓝色框节点就是当前节点。左右上下四个节点都是它的方向节点，那么哪个方向节点对它朝向终点最有影响力的呢？首先可以排除右下两个，因为他们不是朝向终点的。\n剩下左和上两个，最终判定是有视野的，那么上方的阻断并不是最优影响力的，而是左边节点。这里其实可以通过当前节点指向终点的射线来理解，射线方向其实更偏向左边，所以左边是否为有视野对当前节点影响最大。所以左边拥有视野，它也可能拥有视野。\n如上图，如果射线方向是指向对角线（右上角）呢？那对角线隔壁的两个方向节点都拥有相同的影响力，那么两个只要一个拥有视野，它也可能拥有视野。\n这里还要补充一个代码里面有，但没有说明的情况：这两个方向节点都不能为阻挡，因为视野是平分的，有一个为阻挡则表现智能体有一半穿过阻挡节点的角\n朝向终点的对角线：\n还是上面的两个图片来解释另外一个必须的条件。朝向终点的对角线其实比较容易理解，就是射线指向的那个对角线。而这个对角线拥有视野，则说明这个对角线前面也是一览无遗的，那么才能确保它是拥有视野的。\n实现代码：\nfunction calculateLos(at, pathEnd) { var xDif = pathEnd.x - at.x; var yDif = pathEnd.y - at.y; var xDifAbs = Math.abs(xDif); var yDifAbs = Math.abs(yDif); var hasLos = false; var xDifOne = Math.sign(xDif); var yDifOne = Math.sign(yDif); //Check the direction we are furtherest from the destination on (or both if equal) // If it has LOS then we might //Check in the x direction if (xDifAbs \u0026gt;= yDifAbs) { if (losGrid[at.x + xDifOne][at.y]) { hasLos = true; } } //Check in the y direction if (yDifAbs \u0026gt;= xDifAbs) { if (losGrid[at.x][at.y + yDifOne]) { hasLos = true; } } //If we are not a straight line vertically/horizontally to the exit if (yDifAbs \u0026gt; 0 \u0026amp;\u0026amp; xDifAbs \u0026gt; 0) { //If the diagonal doesn\u0026#39;t have LOS, we don\u0026#39;t if (!losGrid[at.x + xDifOne][at.y + yDifOne]) { hasLos = false; } else if (yDifAbs === xDifAbs) { //If we are an exact diagonal and either straight direction is a wall, we don\u0026#39;t have LOS if (dijkstraGrid[at.x + xDifOne][at.y] === Number.MAX_VALUE || dijkstraGrid[at.x][at.y + yDifOne] === Number.MAX_VALUE) { hasLos = false; } } } //It\u0026#39;s a definite now losGrid[at.x][at.y] = hasLos; //TODO: Could replace our distance with a direct distance? // Might not be worth it, would need to use a priority queue for the open list. } 这里代码实现的比较巧妙：\n首先获取节点相对终点的横向、纵向距离和单位方向。 通过横向、纵向距离和单位方向判断出哪个方向节点是对当前节点影响最大的，通过方向节点的视野推出当前节点的视野。 如果不是终点，那接着就是对一些不满足的情况取消视野。 如果对角线没有视野，则取消其视野。（不满足“朝向终点的对角线有视野”条件） 如果横向、纵向距离都相同，则需要判断两个方向节点是否都是非阻挡，有一个为阻挡则取消其视野。（方向节点平分了视野，需要同时为非阻挡） 接着就是在遍历Dijkstra网格时，把视野处理也加上（遍历Dijkstra网格的顺序符合视野的处理顺序，都是从终点开始广度搜索）\n补充说明 “如果朝向终点最有影响力的方向节点有视野，并且朝向终点的对角线有视野，那它也有视野”这条规则其实被作者简化了很多，在特殊情况下，这两个必要条件有可能不满足也有视野。\n例如上图蓝框部分，即使方向节点丢失视野，但它仍然可以拥有视野，这是由于前面的方向节点都受到终点上方的阻挡影响，导致都失去了视野。\n另外一种特殊情况，即使对角线没视野，但它仍然可以拥有视野，例如射线趋近于方向节点时，尽管对角线没有视野，也不能证明它没有视野。例如下图节点12、13（蓝色箭头开始位置）受到的阻挡远远小于节点3（绿色箭头开始位置），但由于这个条件导致丢失视野。\n","ref":"/blog/readingnotes/howtorts/"},{"title":"Unity性能优化技巧汇总","date":"","description":"Unity性能优化技巧汇总","body":"汇总一些简单的性能优化技巧\nPhysics（物理） 减少FixedUpdate调用次数 FixedUpdate是采用固定的调用间隔：Time.fixedDeltaTime，由于是固定调用间隔，因此每帧的调用次数实际上是通过Time.deltaTime/Time.fixedDeltaTime计算出来的，如果当前帧卡顿了，那么FixedUpdate很大可能（超过Time.fixedDeltaTime）会增加调用次数，情况会更糟。\n而通过设置Time.maximumDeltaTime，可以将把次数减少。最终次数为Min(Time.deltaTime, Time.maximumDeltaTime)/Time.fixedDeltaTime，例如默认为0.333，则单帧最大调用次数可以达到17次，而如果改成0.100，则单帧最大调用次数会降到5次。\n有两种修改方式：\n通过菜单：ProjectSetting \u0026gt; Time \u0026gt; Maximum Allowed Timestep修改 1 通过代码：Time.maximumDeltaTime 2 去除physics.processing 即使没有用到物理碰撞功能，但物理逻辑仍然会运行，会产生耗时。这个时候可以关闭Physics.autoSimulation来减少这部分耗时。3\n关闭Physics.autoSimulation后，如果需要射线检测，则需要开启Physics.autoSyncTransforms或者手动调用**Physics.SyncTransforms()**来将Transform的变更同步到物理引擎。\nPhysics.autoSyncTransforms有两个常见的耗时堆栈：Physics.SyncColliderTransform和Physics.SyncRigidbodyTransform，都是在Transform发生变化时才会有计算。\nTime, https://docs.unity3d.com/Manual/class-TimeManager.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTime.maximumDeltaTime, https://docs.unity3d.com/ScriptReference/Time-maximumDeltaTime.html\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n如果Unity没有用到物理部分，应该如何关闭？, https://answer.uwa4d.com/question/6285b2a7b87a4573515d6387\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","ref":"/blog/unity3d/optimization/"},{"title":"Unity URP 优化技巧","date":"","description":"URP的优化技巧","body":"URP项目的优化技巧汇总，由于篇幅问题，部分优化中的原理会在其他文章中详细介绍。\n版本 URP: 10.10.1 Bloom优化 关闭HQ HQ选项能够让Bloom效果更加平滑。这是因为开启HQ后，降采样前会对原图进行一次Blur，然后再升采样时会有部分采用双向三次插值采样。\nHQ开启带来更好的效果，随之而来也带来更大的性能消耗。具体统计数据可以查看URP Bloom效果文章，里面有更详细的分析。\n所以关闭HQ可以带来2~3ms（小米9）的减少，而效果往往不会相差太多。\n降迭代 URP的Bloom算法是通过多次降采样和多次升采样来进行Blur操作的，而往往需要多次迭代来达到Blur的效果。\n但迭代次数多意味着需要多次Blit，而每次Blit都需要等待上一次的结果，所以也无法做到并行处理，而随着迭代次数增多，Blit的尺寸越来越小，后面的Blit并没有充分利用GPU的算力。\n而越往后的低尺寸Blur，实际上并不会对最终效果做出很大权重的贡献。\n综合上述情况，URP Bloom提供了Skip Iterations的选项，可以减少原有的迭代次数:\n//PostProcessPass.CS // Determine the iteration count int maxSize = Mathf.Max(tw, th); int iterations = Mathf.FloorToInt(Mathf.Log(maxSize, 2f) - 1); iterations -= m_Bloom.skipIterations.value; 与关闭HQ一样，具体统计数据可以查看URP Bloom效果文章，里面有更详细的分析。\n所以减少迭代次数可以带来1~2ms（小米9）的减少，而效果往往不会相差太多。\n当然，迭代次数减少也不是越小越好的，需要根据实际情况考虑。\n降采样 Bloom后处理本来就有降采样处理。首先会降1/4（宽高各1/2），然后再逐级下降。\n这个操作本来就已经能降低采样规模，不过还可以进一步减少。\n就是在首次降采样时可以更激进的使用1/8~1/16，这样每级的采样纹理会更较小，可以减少带宽。\n//PostProcessPass.CS void SetupBloom(CommandBuffer cmd, int source, Material uberMaterial) { int tw; int th; if (m_Bloom.downSample.value) { // Start at quarter-res tw = m_Descriptor.width \u0026gt;\u0026gt; 2; th = m_Descriptor.height \u0026gt;\u0026gt; 2; } else { // Start at half-res tw = m_Descriptor.width \u0026gt;\u0026gt; 1; th = m_Descriptor.height \u0026gt;\u0026gt; 1; } //... } 值得注意，这么做并不是没有缺点的：\n纹理越小，锯齿感越明显。特别在高强度的情况下特别明显。\n","ref":"/blog/urp/optimize/"},{"title":"About","date":"","description":"希望这里的教程能给大家提供灵感","body":"Unity 游戏开发\u0026hellip;\n这里主要是想把自己日常开发所遇到的问题、感悟的见解全写出来，为大家提供一些思路和灵感。\n","ref":"/about/"},{"title":"Fantasy Factor","date":"","description":"Unity Tools by Fantasy Factor","body":"email: 2771918131@qq.com\nFantasy Factor Fantasy Factor UnityCompare UCompare A tool for comparing Unity3D Prefabs, quickly comparing differences, copying components, copying properties, etc.\nThe principle is based on the comparison of the subtrees of two Prefabs in sequence (by name), and then the differences are displayed in a tree structure. Then, by clicking in, you can see the differences in the Components of the two sub-GameObjects. After selecting a specific GameObject or Component, you can see the comparison based on SerializedObject and SerializedProperty, and then you can perform editing operations.\nFeature List Compare Prefab Differences Visualize Results Filterable Results Customizable Ignored Properties Quick Copy of GameObject Quick Copy of Component Quick Comparison Menu Synchronized Tree List Component Display Consistent with Unity ","ref":"/fantasyfactor/"},{"title":"URP Bloom效果","date":"","description":"URP Bloom后处理","body":"分析URP的Bloom效果\n原理分析 源码剖析 URP的Bloom是作为后处理实现在PostProcessPass中。C#部分的核心代码有SetupBloom()。\n// Start at half-res int tw = m_Descriptor.width \u0026gt;\u0026gt; 1; int th = m_Descriptor.height \u0026gt;\u0026gt; 1; // Determine the iteration count int maxSize = Mathf.Max(tw, th); int iterations = Mathf.FloorToInt(Mathf.Log(maxSize, 2f) - 1); iterations -= m_Bloom.skipIterations.value; int mipCount = Mathf.Clamp(iterations, 1, k_MaxPyramidSize); 由上文原理分析可知，为了减少模糊时的采样次数，模糊之前首先需要先降一次分辨率，所以先计算分辨率一半的宽高值。\n然后使用半分辨率的宽高值来计算模糊需要迭代的次数（注意：这里并不是Blur的次数），例如2400，则需要迭代9次，然后剔除需要忽略的迭代次数，不开启skipIterations时，skipIterations.value默认为1次，再对迭代次数限制一下，因此最终迭代次数为8次。\nP.S.实际上，这里最后用了mipCount来命名才是较为准确的说法，按照迭代次数的字面理解，应该是Blur的次数（横向+纵向视为一次Blur），但排除了预降采样后，Blur的次数等于mipCount-1。因此用mipCount较为贴切，以2400举例，mip[0]就是1200，mip[1]为600，mip[2]为300\u0026hellip;。而首次Blur就是mip[0]到mip[1]，这样就能理解后续的逻辑。\n//设置材质球属性 //... // Prefilter var desc = GetCompatibleDescriptor(tw, th, m_DefaultHDRFormat); cmd.GetTemporaryRT(ShaderConstants._BloomMipDown[0], desc, FilterMode.Bilinear); cmd.GetTemporaryRT(ShaderConstants._BloomMipUp[0], desc, FilterMode.Bilinear); Blit(cmd, source, ShaderConstants._BloomMipDown[0], bloomMaterial, 0); 首先进行模糊前预处理，其中包含降采样和提取亮部信息。\n#if _BLOOM_HQ float texelSize = _SourceTex_TexelSize.x; half4 A = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(-1.0, -1.0)); half4 B = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(0.0, -1.0)); half4 C = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(1.0, -1.0)); half4 D = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(-0.5, -0.5)); half4 E = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(0.5, -0.5)); half4 F = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(-1.0, 0.0)); half4 G = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv); half4 H = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(1.0, 0.0)); half4 I = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(-0.5, 0.5)); half4 J = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(0.5, 0.5)); half4 K = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(-1.0, 1.0)); half4 L = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(0.0, 1.0)); half4 M = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + texelSize * float2(1.0, 1.0)); half2 div = (1.0 / 4.0) * half2(0.5, 0.125); half4 o = (D + E + I + J) * div.x; o += (A + B + G + F) * div.y; o += (B + C + H + G) * div.y; o += (F + G + L + K) * div.y; o += (G + H + M + L) * div.y; half3 color = o.xyz; #else half3 color = SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv).xyz; #endif 降采样为了减少后续模糊的采样的性能压力，由于对画质有不同的要求，所以会有High Quality Filtering（后续简称HQ）的选项。\n可以看出，在正常状态下直接采样，然后利用纹理的双向二次插值来平滑。\n而开启HQ后，将会对原始纹理进行一次Blur处理，这样效果会更好，随之而来的是性能开销也会更大。\n接下来就是gaussian pyramid，这是降采样的高斯模糊算法。\nint lastDown = ShaderConstants._BloomMipDown[0]; for (int i = 1; i \u0026lt; mipCount; i++) { tw = Mathf.Max(1, tw \u0026gt;\u0026gt; 1); th = Mathf.Max(1, th \u0026gt;\u0026gt; 1); int mipDown = ShaderConstants._BloomMipDown[i]; int mipUp = ShaderConstants._BloomMipUp[i]; desc.width = tw; desc.height = th; cmd.GetTemporaryRT(mipDown, desc, FilterMode.Bilinear); cmd.GetTemporaryRT(mipUp, desc, FilterMode.Bilinear); Blit(cmd, lastDown, mipUp, bloomMaterial, 1); Blit(cmd, mipUp, mipDown, bloomMaterial, 2); lastDown = mipDown; } 每次循环，纹理都会降到原来的1/4，这样的好处是可以通过采样的双向二次插值来代替部分卷积计算。\n然后采用横向和纵向分别做高斯模糊的方式（常见的优化手段，通过拆分来减少采样次数）。\n// FragBlurH() // 9-tap gaussian blur on the downsampled source half3 c0 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv - float2(texelSize * 4.0, 0.0))); half3 c1 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv - float2(texelSize * 3.0, 0.0))); half3 c2 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv - float2(texelSize * 2.0, 0.0))); half3 c3 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv - float2(texelSize * 1.0, 0.0))); half3 c4 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv )); half3 c5 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + float2(texelSize * 1.0, 0.0))); half3 c6 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + float2(texelSize * 2.0, 0.0))); half3 c7 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + float2(texelSize * 3.0, 0.0))); half3 c8 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + float2(texelSize * 4.0, 0.0))); half3 color = c0 * 0.01621622 + c1 * 0.05405405 + c2 * 0.12162162 + c3 * 0.19459459 + c4 * 0.22702703 + c5 * 0.19459459 + c6 * 0.12162162 + c7 * 0.05405405 + c8 * 0.01621622; // FragBlurV() // Optimized bilinear 5-tap gaussian on the same-sized source (9-tap equivalent) half3 c0 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv - float2(0.0, texelSize * 3.23076923))); half3 c1 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv - float2(0.0, texelSize * 1.38461538))); half3 c2 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv )); half3 c3 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + float2(0.0, texelSize * 1.38461538))); half3 c4 = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv + float2(0.0, texelSize * 3.23076923))); half3 color = c0 * 0.07027027 + c1 * 0.31621622 + c2 * 0.22702703 + c3 * 0.31621622 + c4 * 0.07027027; 可以看出来，横向采样了9个点，而纵向则只采样5个点。这是因为横向的输入纹理是原纹理，而到纵向时，输入纹理是已经降分辨率的纹理，由于降采样已经对纵向进行了一次平均计算（双向二次插值）,所以只需要5个点也能达到模糊效果。\n// Upsample (bilinear by default, HQ filtering does bicubic instead for (int i = mipCount - 2; i \u0026gt;= 0; i--) { int lowMip = (i == mipCount - 2) ? ShaderConstants._BloomMipDown[i + 1] : ShaderConstants._BloomMipUp[i + 1]; int highMip = ShaderConstants._BloomMipDown[i]; int dst = ShaderConstants._BloomMipUp[i]; cmd.SetGlobalTexture(ShaderConstants._SourceTexLowMip, lowMip); Blit(cmd, highMip, BlitDstDiscardContent(cmd, dst), bloomMaterial, 3); } half3 Upsample(float2 uv) { half3 highMip = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTex, sampler_LinearClamp, uv)); #if _BLOOM_HQ \u0026amp;\u0026amp; !defined(SHADER_API_GLES) half3 lowMip = DecodeHDR(SampleTexture2DBicubic(TEXTURE2D_X_ARGS(_SourceTexLowMip, sampler_LinearClamp), uv, _SourceTexLowMip_TexelSize.zwxy, (1.0).xx, unity_StereoEyeIndex)); #else half3 lowMip = DecodeHDR(SAMPLE_TEXTURE2D_X(_SourceTexLowMip, sampler_LinearClamp, uv)); #endif return lerp(highMip, lowMip, Scatter); } 非HQ状态下，每次升采样都会用highMip(n+1)和lowMip(n)进行一次插值混合，混合比例就是Scatter值，这样能控制模糊的散射程度。\n在HQ状态下，一样是使用highMip和lowMip进行混合，唯一的不同就是获取lowMip是使用了双向三次插值来进行采样。这样获取的颜色值会进一步平滑，但随之而来的就是性能消耗也随之提升。\n性能优化 简单优化 根据上面源码分析可知，开了HQ性能会下降，HQ首次缩放时会对原图（全屏尺寸）做了一次模糊（单个像素做13次采样），升采样阶段又会调用SampleTexture2DBicubic做了双向三次插值计算，这两部分额外的采样和计算导致了开启HQ后耗时增加。\n另外URP Bloom在升降采样过程中，默认的缩放次数其实比较高，也就是Blit次数较多，按照2400*1080的尺寸，迭代次数为9次，mip为8（8 = 9 - 1，默认忽略一次）， 按Prefilter（1次）、降采样（7次*2）、升采样（7次），默认一共需要做22次Blit。而我们知道移动端对于处理Blit其实也有耗时，而且当纹理小的一定程度时，对于Blur的影响将会减少。根据游戏画面影响程度，笔者将Skip iterations设为6，mip为3(3 = 9 - 6)，Blur的次数也就降为2，而Blit的次数也减少到7次。\n最后在小米9测出来优化前后影响（由于受到发热降频影响，数据可能跟实际有少许出入）：\n描述 帧率 耗时 开启HQ、没有限制迭代次数 23 43ms 关闭HQ、没有限制迭代次数 25 40ms 关闭HQ、限制到两次 26 38ms 可以看出，在经过调整参数来优化后，整体的耗时能减少5ms，而效果并没有太大的差别。\n粗暴的对比一下优化前后的Sample次数，就能知道为什么能减少那么耗时了（N为屏幕尺寸像素数量，T为迭代次数）：\nPrefilter： 关闭HQ：$N$ 开启HQ：$P = 13 * N$ DownHorizontal： $DH = 9 * (\\frac{1}{4}N + \\frac{1}{16}N + \\frac{1}{64}N + ...) \\Rightarrow DH = 9 * \\frac{1 - (\\frac{1}{4})^T}{3}N $ DownVertical： $DV = 5 * (\\frac{1}{16}N + \\frac{1}{64}N + \\frac{1}{256}N + ...) = \\Rightarrow DH = 5 * \\frac{1}{4} * \\frac{1 - (\\frac{1}{4})^T}{3}N $ Up： 关闭HQ：$UP = (\\frac{1}{4}N + \\frac{1}{16}N + \\frac{1}{64}N + ...) \\Rightarrow DH = \\frac{1 - (\\frac{1}{4})^T}{3}N $ 开启HQ：$UP = 4 * (\\frac{1}{4}N + \\frac{1}{16}N + \\frac{1}{64}N + ...) \\Rightarrow DH = 4 * \\frac{1 - (\\frac{1}{4})^T}{3}N $ 描述 Blit次数 采样次数 开启HQ、没有限制迭代次数 22 17.74971*N 关闭HQ、没有限制迭代次数 22 4.74977*N 关闭HQ、限制到两次 7 4.515625*N Dual Blur算法 Dual (Kawase) Blur算法跟URP的Bloom算法都采用了降采样、升采样来优化模糊算法，唯一的不同是URP使用的是高斯模糊加降采样，而Dual是采用Kawase加降采样。\nDual从算法来说就是DownHorizontal和DownVertical合并为一个，只降采样中间和四个角落顶点。升采样则对中心周边八个顶点进行采样。\n对比来说，两者的采样次数其实相差无几，但Blit次数可以减少1/3左右。综合来说两者性能实际上差别是有的，但没有预想中那么大。\n","ref":"/blog/urp/postprocess_bloom/"},{"title":"lua fulluserdata代替table的尝试","date":"","description":"lua fulluserdata代替table的尝试","body":"使用fulluserdata来实现复杂的数据结构，然后尝试替代table，以验证是否可以实现更快的框架（Table的Value为Table时，会有内存不连续的情况，缓存不友好）\n环境 xlua版本：2.1.16 lua版本：5.3.5 运行环境：Unity Editor PC配置：i5 10400F 为了方便测试，所有的测试基于Unity Editor(PC)环境，采用Unity Profiler和Lua Profiler。\nArray 以fulluserdata为基础，在C实现了一个Array[double]。\nluaarray.h:\n#ifndef LUAARRAY_H #define LUAARRAY_H #include \u0026#34;lua.h\u0026#34; /*-------------------------------------------------------------------------*\\ * Initializes the library. \\*-------------------------------------------------------------------------*/ LUA_API int luaopen_array(lua_State *L); #endif /* LUAARRAY_H */ luaarray.c:\n#include \u0026#34;luaarray.h\u0026#34; #define LUA_LIB #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; #include \u0026#34;limits.h\u0026#34; #define ARRAY_TAG \u0026#34;LuaArrayMatetable\u0026#34; typedef struct NumArray { int size; double values[1]; } NumArray; static NumArray *checkarray(lua_State *L) { void *ud = luaL_checkudata(L, 1, ARRAY_TAG); luaL_argcheck(L, ud != NULL, 1, \u0026#34;\u0026#39;array\u0026#39; expected\u0026#34;); return (NumArray *)ud; } static double *getelement(lua_State *L) { NumArray *a = checkarray(L); int index = luaL_checkinteger(L,2) - 1; luaL_argcheck(L,a != NULL,1,\u0026#34;\u0026#39;array\u0026#39; expected.\u0026#34;); luaL_argcheck(L,0 \u0026lt;= index \u0026amp;\u0026amp; index \u0026lt; a-\u0026gt;size,2,\u0026#34;index out of range.\u0026#34;); return \u0026amp;a-\u0026gt;values[index]; } static int newarray(lua_State* L) { int i, n; n = luaL_checkinteger(L,1); luaL_argcheck(L, n \u0026gt;= 1, 1, \u0026#34;invalid size.\u0026#34;); size_t nbytes = sizeof(NumArray) + (n - 1) * sizeof(double); NumArray* a = (NumArray*) lua_newuserdata(L,nbytes); a-\u0026gt;size = n; for (i = 0; i \u0026lt; n - 1; ++i) a-\u0026gt;values[i] = 0; luaL_getmetatable(L, ARRAY_TAG); lua_setmetatable(L, -2); return 1; } static int setarray(lua_State* L) { double value = luaL_checknumber(L, 3); *getelement(L) = value; return 0; } static int getarray(lua_State* L) { lua_pushnumber(L, *getelement(L)); return 1; } static int getsize(lua_State* L) { NumArray *a = checkarray(L); lua_pushnumber(L, a-\u0026gt;size); return 1; } static int array2string(lua_State* L) { NumArray* a = checkarray(L); lua_pushfstring(L,\u0026#34;array(%d)\u0026#34;,a-\u0026gt;size); return 1; } static luaL_Reg arraylib_f [] = { {\u0026#34;new\u0026#34;, newarray}, {NULL, NULL} }; static luaL_Reg arraylib_m [] = { {\u0026#34;set\u0026#34;, setarray}, {\u0026#34;get\u0026#34;, getarray}, {\u0026#34;size\u0026#34;, getsize}, {\u0026#34;__tostring\u0026#34;, array2string}, {NULL, NULL} }; LUA_API int luaopen_array(lua_State* L) { luaL_newmetatable(L, ARRAY_TAG); lua_pushstring(L, \u0026#34;__index\u0026#34;); lua_pushvalue(L, -2); lua_settable(L, -3); luaL_setfuncs(L, arraylib_m, 0); luaL_newlib(L, arraylib_f); return 1; } 对比 local array = require \u0026#34;array\u0026#34; local num = 1000000 function TestTable() local time = os.clock() local tb = {} local value time = os.clock() local insert = table.insert for i=1,num do tb[i] = i end print(string.format(\u0026#34;set table: %sms\u0026#34;, (os.clock() - time) * 1000)) time = os.clock() for i=1,num do value = tb[i] end print(string.format(\u0026#34;get table:%sms\u0026#34;, (os.clock() - time) * 1000)) end function TestUserdata() local time = os.clock() local arr = array.new(num) local value time = os.clock() for i=1,num do arr:set(i, i) end print(string.format(\u0026#34;set array: %sms\u0026#34;, (os.clock() - time) * 1000)) time = os.clock() for i=1,num do value = arr:get(i) end print(string.format(\u0026#34;get array:%sms\u0026#34;, (os.clock() - time) * 1000)) end print(num) TestUserdata() TestTable() 在完成luaarray.c的实现后，就编写基于两者的对比用例，并且在unity中进行测试。原本以为fulluserdata的实现会比table性能好，最差也是相差无几，但实际情况却出人意料：\n方案 set耗时(ms) get耗时（ms） Table 24 9 Array 82 79 优化Array 从上面对比的情况可以看出，Table远远比Array快，特别在get的情况。在经过一番思考过后，排查出一个问题：那就是Array由于需要区分当前userdata类型，防止意外的内存指针传入导致出问题，所以使用了metatable，所以在调用时，会先判断metatable的情况。以此作为优化目标进行优化：\nstatic NumArray *checkarray(lua_State *L) { // 不再检查matetable //void *ud = luaL_checkudata(L, 1, ARRAY_TAG); void *ud = lua_touserdata(L, 1); luaL_argcheck(L, ud != NULL, 1, \u0026#34;\u0026#39;array\u0026#39; expected\u0026#34;); return (NumArray *)ud; } static int newarray(lua_State* L) { int i, n; n = luaL_checkinteger(L,1); luaL_argcheck(L, n \u0026gt;= 1, 1, \u0026#34;invalid size.\u0026#34;); size_t nbytes = sizeof(NumArray) + (n - 1) * sizeof(double); NumArray* a = (NumArray*) lua_newuserdata(L,nbytes); a-\u0026gt;size = n; for (i = 0; i \u0026lt; n - 1; ++i) a-\u0026gt;values[i] = 0; // 不再设置metatable //luaL_getmetatable(L, ARRAY_TAG); //lua_setmetatable(L, -2); return 1; } //将function赋值给array static luaL_Reg arraylib_f [] = { {\u0026#34;new\u0026#34;, newarray}, {\u0026#34;set\u0026#34;, setarray}, {\u0026#34;get\u0026#34;, getarray}, {\u0026#34;size\u0026#34;, getsize}, {\u0026#34;__tostring\u0026#34;, array2string}, //print(a)时Lua会调用该元方法。 {NULL, NULL} }; function TestUserdata() local time = os.clock() local arr = array.new(num) local value time = os.clock() local set = array.set --改为array的function，并缓存起来 for i=1,num do set(arr, i, i) end print(string.format(\u0026#34;set array: %sms\u0026#34;, (os.clock() - time) * 1000)) time = os.clock() local get = array.get --改为array的function，并缓存起来 for i=1,num do value = get(arr, i) end print(string.format(\u0026#34;get array:%sms\u0026#34;, (os.clock() - time) * 1000)) end 测试后，耗时有所改善，但仍然不太乐观：\n方案 set耗时(ms) get耗时（ms） Table 24 9 Array (no metatable) 44 38 可以看出，metatable对于代码效率影响巨大。如果需要标记当前的内存指针是否正确，就需要另辟蹊径。\n分析 首先分析table的set耗时为什么比table的get要高？ 这是因为table插入数据时存在扩容的情况。\ntable的set为什么比array快？ 这是有两个原因。\n一是示例中的table放入的是number值，number值在table的Value中是以连续内存存在的，这是因为TValue是一个联合体，在number的情况下TValue就保存着值，因此内存是连续的，就不存在缓存不友好的情况。\n二是table[x]在运行时是使用OP_SETTABLE和OP_GETTABLE两个指令。而示例中的array.set则需要使用多次OP_MOVE，最后还要调用OP_CALL，在指令中不占优，并且需要频繁操作寄存器导致耗时较大。\nlocal array = require \u0026#34;array\u0026#34; local num = 1000 local a = {} for i=1,num do a[i] = i end main \u0026lt;table.lua:0,0\u0026gt; (12 instructions at 0000000000028a70) 0+ params, 7 slots, 1 upvalue, 7 locals, 4 constants, 0 functions 1 [1] GETTABUP 0 0 -1 ; _ENV \u0026#34;require\u0026#34; 2 [1] LOADK 1 -2 ; \u0026#34;array\u0026#34; 3 [1] CALL 0 2 2 4 [3] LOADK 1 -3 ; 1000 5 [5] NEWTABLE 2 0 0 6 [7] LOADK 3 -4 ; 1 7 [7] MOVE 4 1 8 [7] LOADK 5 -4 ; 1 9 [7] FORPREP 3 1 ; to 11 10 [8] SETTABLE 2 6 6 11 [7] FORLOOP 3 -2 ; to 10 12 [9] RETURN 0 1 local array = require \u0026#34;array\u0026#34; local num = 1000 local arr = array.new(num) local set = array.set for i=1,num do set(arr, i, i) end main \u0026lt;table.lua:0,0\u0026gt; (19 instructions at 00000000001b8a70) 0+ params, 12 slots, 1 upvalue, 8 locals, 6 constants, 0 functions 1 [1] GETTABUP 0 0 -1 ; _ENV \u0026#34;require\u0026#34; 2 [1] LOADK 1 -2 ; \u0026#34;array\u0026#34; 3 [1] CALL 0 2 2 4 [3] LOADK 1 -3 ; 1000 5 [11] GETTABLE 2 0 -4 ; \u0026#34;new\u0026#34; 6 [11] MOVE 3 1 7 [11] CALL 2 2 2 8 [13] GETTABLE 3 0 -5 ; \u0026#34;set\u0026#34; 9 [15] LOADK 4 -6 ; 1 10 [15] MOVE 5 1 11 [15] LOADK 6 -6 ; 1 12 [15] FORPREP 4 5 ; to 18 13 [16] MOVE 8 3 14 [16] MOVE 9 2 15 [16] MOVE 10 7 16 [16] MOVE 11 7 17 [16] CALL 8 4 1 18 [15] FORLOOP 4 -6 ; to 13 19 [17] RETURN 0 1 复杂场景 上述的示例只是一个很简单的场景，在实际开发中，往往会比这个更加复杂，例如实体是一个复杂的结构，可能是面向对象（存在元表），管理时也会对实体增删查改。\n而访问元表、table的创建删除、table的扩容都是较为耗时的操作。\n800个单位的碰撞测试（未优化过算法，碰撞测试次数在800 * 800 * 0.5 = 320000）。测试场景中只是简单模拟了实体的创建和获取，至于隐藏在实体框架中的耗时并没有包含在测试过程（例如框架的继承需要用到元表、C侧的框架逻辑），因此只是比较了Lua Table和Userdata对于复杂数据的读写耗时。\n为了快速验证，本次测试只封装了Component读的方法，写的方法还是采用旧的方案\nstatic int getcomponents(lua_State* L) { NumArray *a = checkarray(L); int index = luaL_checkinteger(L,2) - 1; int entityGroup = luaL_checkinteger(L,3); //实际情况下，需要告知实体管理需要获取哪些Component，这里模拟了参数传入 int start = index * 9; int end = start + 9 - 1; luaL_argcheck(L,a != NULL,1,\u0026#34;\u0026#39;array\u0026#39; expected.\u0026#34;); luaL_argcheck(L,0 \u0026lt;= index \u0026amp;\u0026amp; end \u0026lt; a-\u0026gt;size,2,\u0026#34;index out of range.\u0026#34;); for (size_t i = 0; i \u0026lt; 9; i++) { lua_pushnumber(L, a-\u0026gt;values[start + i]); } return 9; } 方案 create耗时(ms) 碰撞检测耗时（ms） Table（结构） 1 41 Table（连续内存） 1 41 Component 1 31 可以看出来，Lua Table在复杂情况下是比userdata要更耗时的，这也比较好理解，userdata一次性全返回了需要的Component属性，这样子就可以减少函数调用和参数入栈出栈次数，而table不管是结构和连续内存，都需要重复的压入索引或获取返回值，这样OP_SETTABLE和OP_GETTABLE的优势将荡然无存。\n假设再加上实体框架的逻辑，那么userdata方案将会比table更有优势，因为lua侧只能是用table和metatable来进行管理，而userdata将大量的实体管理逻辑隐藏在C侧。\n","ref":"/blog/lua/fulluserdataexperiment/"},{"title":"xlua Delegate 泄漏检查","date":"","description":"xlua Delegate 泄漏检查","body":"排查和定位xLua中Delegate没有销毁的情况\n前言 笔者在开发项目时，发现在xLua Dispose时总是会有DelegateBridge没有移除的情况，这有很多原因导致的，其中除了有之前讨论过的《UnityEvent引起的内存泄漏》，也不乏一些日常写业务逻辑疏忽导致的。但无论哪种情况，在销毁xLua虚拟机前调用多次GC释放，而仍然存在的DelegateBridge就代表原来Lua逻辑有未正常销毁的情况，这体现其背后可能存在内存泄漏等问题，而本篇文章就是研究如何去找到没有释放所引用的Lua代码位置。\nInvalidOperationException: try to dispose a LuaEnv with C# callback! 源码方案 xLua在虚拟机销毁前，会先调用多次GC，然后再释放ObjectTranslator的对象。\n//调用多次GC是为了让Lua和C#之间没有引用关系的对象得以释放。 public void Dispose() { FullGc(); System.GC.Collect(); System.GC.WaitForPendingFinalizers(); Dispose(true); System.GC.Collect(); System.GC.WaitForPendingFinalizers(); } 而在Dispose ObjectTranslator时，会释放掉所有的DelegateBridge。在释放每一个DelegateBridge都会先确认是否存活（IsAlive），如果有一个则会抛出异常。\nif (!translator.AllDelegateBridgeReleased()) { throw new InvalidOperationException(\u0026#34;try to dispose a LuaEnv with C# callback!\u0026#34;); } 由于信息有限，所以并不知道是哪个对象哪句代码所注册Delegate，因此需要扩展对应的检查。\n输出Delegate信息 首先较为简单的方案就是把没有释放的Delegate信息输出出来，其中包括Method的名称、类型等。\n//Class DelegateBridgeBase public string GetMessage() { StringBuilder builder = new StringBuilder(); if(bindTo != null) { foreach (var item in bindTo) { if (item.Value != null) { builder.AppendFormat(\u0026#34;key:{0} methodName:{1} FullyQualifiedName:{2}\\n\u0026#34;, item.Key, item.Value.Method.Name, item.Value.Method.DeclaringType.Name); } } } else if(firstValue != null) { builder.AppendFormat(\u0026#34;key:{0} methodName:{1} FullyQualifiedName:{2}\\n\u0026#34;, firstKey, firstValue.Method.Name, firstValue.Method.DeclaringType.Name); } return builder.ToString(); } //Class ObjectTranslator public bool AllDelegateBridgeReleased(IntPtr L, ref string message) { StringBuilder builder = new StringBuilder(); bool result = true; foreach (var kv in delegate_bridges) { if (kv.Value.IsAlive) { builder.AppendLine(delegateBridgeBase.GetInfo()); } } message = builder.ToString(); return result; } 这样就可以获取到所有没有释放的Delegate信息了。\ndebug.traceback 虽然获取Delegate信息能找到一些蛛丝马迹，但其实还远远不够，因为相同类型的Delegate实在太多了，而且如果是反射Warp的方式，类似methodName:__Gen_Delegate_Imp7 FullyQualifiedName:XLuaGenDelegateImpl0的信息一点用都没有。这时候就需要增加其他方法来获取更精确的信息了，例如获取Lua堆栈信息。\nlua有一个debug.traceback()的API是可以获取到当前Lua逻辑中的堆栈信息的。\n//在C#端增加以下逻辑 private string GetStack(RealStatePtr L) { var oldTop = LuaAPI.lua_gettop(L); int debug = LuaAPI.xlua_getglobal(L, \u0026#34;debug\u0026#34;); LuaAPI.xlua_pushasciistring(L, \u0026#34;traceback\u0026#34;); LuaAPI.xlua_pgettable(L, -2); var index = LuaAPI.lua_pcall(L, 0, 1, 0); string luaStack = LuaAPI.lua_tostring(L, -1); LuaAPI.lua_pop(L, 2); LuaAPI.lua_settop(L, oldTop); return luaStack; } 尝试在ObjectTranslator.CreateDelegateBridge()调用，输出日志：\nstack traceback: [C]:in local \u0026#39;loadFun\u0026#39; Script/B:12: in field\u0026#39;Fun2\u0026#39; Script/A:32: in field\u0026#39;Fun1\u0026#39; ...... 这样就可以在创建DelegateBridge时获取到调用的Lua代码堆栈，然后保存起来，等销毁时把没有释放的堆栈信息输出。\n//将原来的CreateDelegateBridge方法改成私有，把weakReference作为out结果返回。 private object CreateDelegateBridge(RealStatePtr L, Type delegateType, int idx, out WeakReference weakReference) { ... } //增加新的CreateDelegateBridge提供给外部调用 public object CreateDelegateBridge(RealStatePtr L, Type delegateType, int idx) { WeakReference weakReference = null; var stack = this.GetStack(L); var result = CreateDelegateBridge(L, delegateType, idx, out weakReference); if(weakReference != null) { int hash = weakReference.GetHashCode(); //利用weakReference的哈希值来作为key bridgesReferenceInfos[hash] = stack; } return result; } AllDelegateBridgeReleased和ReleaseLuaBase也需要根据weakReference.GetHashCode()处理（获取信息和释放），这里就不再赘述了。\ndebug.getinfo 其实使用traceback已经能完美解决问题了，为什么还有下文呢？这是因为笔者在接入到项目后，发现项目变的很卡，特别是在创建模块（场景、界面）时。在一轮抽丝剥茧后，发现了debug.traceback是一个性能消耗巨大的API，在Editor下十次调用就有100ms，这即使在Editor下也是不可接受的。\n所以在一轮查找后，笔者找到了debug.getinfo的方法来实现功能。\n-- 获取当前调用层级所在的lua文件路径 -- 1就是第一层 debug.getinfo(1, \u0026#34;S\u0026#34;).source -- 获取当前调用层级（代码堆栈）所在的行号 -- 1就是第一层 debug.getinfo(1, \u0026#34;l\u0026#34;).currentline 在C#侧增加了接口，替代了原来的GetStack()。\nprivate string GetInfo(RealStatePtr L, int maxLevel = 5) { luaStackBuffer.Clear(); var oldTop = LuaAPI.lua_gettop(L); int debug = LuaAPI.xlua_getglobal(L, \u0026#34;debug\u0026#34;); LuaAPI.xlua_pushasciistring(L, \u0026#34;getinfo\u0026#34;); LuaAPI.xlua_pgettable(L, -2); for (int i = 0; i \u0026lt; maxLevel; i++) { LuaAPI.lua_pushvalue(L, -1); int level = i + 2; //1为C端，没必要输出 LuaAPI.xlua_pushinteger(L, level); //参数 LuaAPI.xlua_pushasciistring(L, \u0026#34;S\u0026#34;); //参数 LuaAPI.lua_pcall(L, 2, 1, 0); if (LuaAPI.lua_isnil(L, -1)) //当前节点是nil，表明没有上一层 { LuaAPI.lua_pop(L, 1); break; } LuaAPI.xlua_pushasciistring(L, \u0026#34;source\u0026#34;); LuaAPI.xlua_pgettable(L, -2); string luaPath = LuaAPI.lua_tostring(L, -1); LuaAPI.lua_pop(L, 2); LuaAPI.lua_pushvalue(L, -1); LuaAPI.xlua_pushinteger(L, level); //参数 LuaAPI.xlua_pushasciistring(L, \u0026#34;l\u0026#34;); //参数 LuaAPI.lua_pcall(L, 2, 1, 0); LuaAPI.xlua_pushasciistring(L, \u0026#34;currentline\u0026#34;); LuaAPI.xlua_pgettable(L, -2); int line = LuaAPI.xlua_tointeger(L, -1); luaStackBuffer.AppendFormat(\u0026#34;{0}: {1}\\n\u0026#34;, luaPath, line); LuaAPI.lua_pop(L, 2); } LuaAPI.lua_pop(L, 2); LuaAPI.lua_settop(L, oldTop); return luaStackBuffer.ToString(); } @Script/B: 12 @Script/A: 32 测试了一下性能，比traceback好一点，但也有80ms/10次。这也是万万不可接受的。\n所以调试了其他方案，最后可以使用linedefined来替代currentline。linedefined与currentline不一样的地方就是，只能获取到当前function开始所在的行号，而不能获得代码精确的行号。\n-- 获取当前调用层级所在的lua文件路径 -- 1就是第一层 debug.getinfo(1, \u0026#34;S\u0026#34;).source -- 获取当前调用层级调用函数所在的行号 -- 1就是第一层 debug.getinfo(1, \u0026#34;S\u0026#34;).linedefined 修改原来的GetInfo()。\nprivate string GetInfo(RealStatePtr L, int maxLevel = 5) { luaStackBuffer.Clear(); var oldTop = LuaAPI.lua_gettop(L); int debug = LuaAPI.xlua_getglobal(L, \u0026#34;debug\u0026#34;); LuaAPI.xlua_pushasciistring(L, \u0026#34;getinfo\u0026#34;); LuaAPI.xlua_pgettable(L, -2); for (int i = 0; i \u0026lt; maxLevel; i++) { LuaAPI.lua_pushvalue(L, -1); int level = i + 2; //1为C端，没必要输出 LuaAPI.xlua_pushinteger(L, level); //参数 LuaAPI.xlua_pushasciistring(L, \u0026#34;S\u0026#34;); //参数 var index = LuaAPI.lua_pcall(L, 2, 1, 0); if(LuaAPI.lua_isnil(L, -1)) //当前节点是nil，表明没有上一层 { LuaAPI.lua_pop(L, 1); break; } LuaAPI.xlua_pushasciistring(L, \u0026#34;source\u0026#34;); LuaAPI.xlua_pgettable(L, -2); string luaPath = LuaAPI.lua_tostring(L, -1); LuaAPI.lua_pop(L, 1); LuaAPI.xlua_pushasciistring(L, \u0026#34;linedefined\u0026#34;); LuaAPI.xlua_pgettable(L, -2); int line = LuaAPI.xlua_tointeger(L, -1); luaStackBuffer.AppendFormat(\u0026#34;{0}: {1}\\n\u0026#34;, luaPath, line); LuaAPI.lua_pop(L, 2); } LuaAPI.lua_pop(L, 2); LuaAPI.lua_settop(L, oldTop); return luaStackBuffer.ToString(); } @Script/B: 5 @Script/A: 30 改进后的方案所得到的堆栈信息可能没有那么的准确（因为没有精确的堆栈行号），但有lua代码地址和函数名已经能大大缩小其范围，相对耗时（一百倍）来说，具有极高的性价比。\n以下是三种方式的对比：\n方案 耗时（ms/10次） traceback 112 getinfo（精确行号） 83 getinfo（函数行号） 1 总结 在通过一系列测试，最后采用了debug.getinfo的方式来获取堆栈，并且采用一个消耗极低的方式获取到对应的函数行号，从而方便定位到问题的模块。如果想要更精确可以和debug.traceback结合处理，日常使用低耗版本监控，有需要定位时采用精确定位。\n","ref":"/blog/xlua/delegatememoryleak/"},{"title":"Unity URP issue","date":"","description":"URP的疑难杂症","body":"总结在URP项目中遇到的疑难杂症\n版本 URP: 10.10.1 URP合批失败 隐藏的Keywords导致的合批失败 问题描述：\n开启了SRP Batch时，两个模型使用了相同的shader，并且使用相同的变体，但无法SRP合批。 在FrameDebugger中提示“SRP:Node use different shader keywords”，但使用中的keywords是一样的。 问题原因：\n材质球中残留了关键字导致的，虽然在实际使用中并没有用到，但Unity会认为两者使用了不同变体，而不会让其合批。 例如创建了材质球，先使用shaderA（例如lit.shader），调整了自发光设置，材质就会多了_EMISSION关键字，然后再替换成shaderB（没有_EMISSION关键字），这样材质球就残留了对应的keyword，而实际上shaderB没有_EMISSION和对应的变体。 参考：\nSRP Batch竟然和RenderQueue有关，有解吗\n打包shader丢失Pass/Variant 打包出来的shader（安装包、ab包）会丢失掉Pass、Variant等。\n问题描述：\n打包出来的shader（安装包、ab包）会丢失掉LightMode为ShadowCaster的Pass。 检查了Shader并没有问题 Editor下运行没有问题 Editor下查看shader编译的文件没有问题 问题原因：\nUnityEditor.Rendering.Universal.ShaderPreprocessor在检测GraphicsSettings和QualitySettings中的PipelineAsset时，发现没有supportsMainLightShadows和supportsAdditionalLightShadows时，会剔除掉LightMode为ShadowCaster的Pass。 ShaderFeatures 记录shader特性的枚举值，可用于后续剔除Pass、Variants的枚举值\nFeature 说明 条件 MainLight 主光源 一定激活 MainLightShadows 主光源阴影 supportsMainLightShadows AdditionalLights 多光源 additionalLightsRenderingMode == LightRenderingMode.PerPixel AdditionalLightShadows 多光源阴影 AdditionalLights \u0026amp;\u0026amp; supportsAdditionalLightShadows VertexLighting 顶点光照 additionalLightsRenderingMode == LightRenderingMode.PerVertex SoftShadows 软阴影 (MainLightShadows || AdditionalLightShadows) \u0026amp;\u0026amp; supportsSoftShadows MixedLighting 混合光照 supportsMixedLighting TerrainHoles 地形挖空 supportsTerrainHoles DeferredShading 延迟渲染 renderingMode == RenderingMode.Deferred DeferredWithAccurateGbufferNormals 高精度GBuffer法线纹理\n（延迟渲染） 所有Renderer.accurateGbufferNormals == true DeferredWithoutAccurateGbufferNormals 非高精确GBuffer法线纹理\n（延迟渲染） 所有Renderer.accurateGbufferNormals == false ScreenSpaceOcclusion 屏幕空间环境光遮蔽\n（SSAO） 任意Renderer激活ScreenSpaceAmbientOcclusion StripUnusedFeatures 主要为剔除没有使用的特性，剔除情况如下：\nKeyword 说明 剔除条件 _MAIN_LIGHT_SHADOWS 主光源阴影 ShaderFeatures.MainLightShadows未激活 _MAIN_LIGHT_SHADOWS_CASCADE 主光源级联阴影 ShaderFeatures.MainLightShadows未激活 _SHADOWS_SOFT 软阴影 ShaderFeatures.SoftShadows未激活 _MIXED_LIGHTING_SUBTRACTIVE 混合光照相减 ShaderFeatures.MixedLighting未激活 LIGHTMAP_SHADOW_MIXING 光照贴图混合 ShaderFeatures.MixedLighting未激活 SHADOWS_SHADOWMASK 阴影遮罩 ShaderFeatures.MixedLighting未激活 _ADDITIONAL_LIGHT_SHADOWS 多光源阴影 ShaderFeatures.AdditionalLightShadows或ShaderFeatures.AdditionalLightShadows未激活 _DEFERRED_ADDITIONAL_LIGHT_SHADOWS 多光源阴影（延迟渲染） ShaderFeatures.AdditionalLightShadows未激活 _ADDITIONAL_LIGHTS 多光源（逐像素） ShaderFeatures.AdditionalLights未激活 _ADDITIONAL_LIGHTS_VERTEX 多光源（逐顶点） ShaderFeatures.VertexLighting未激活 _SCREEN_SPACE_OCCLUSION 屏幕空间环境光遮蔽 ShaderFeatures.ScreenSpaceOcclusion未激活 StripInvalidVariants 主要为剔除不合法的shader变体，剔除情况如下：\nKeyword 说明 剔除条件 _MAIN_LIGHT_SHADOWS_CASCADE 主光源的级联阴影 _MAIN_LIGHT_SHADOWS未激活 _ADDITIONAL_LIGHT_SHADOWS 多光源阴影 _ADDITIONAL_LIGHTS未激活 _DEFERRED_ADDITIONAL_LIGHT_SHADOWS 多光源阴影（延迟渲染） _ADDITIONAL_LIGHTS未激活 _SHADOWS_SOFT 软阴影 _MAIN_LIGHT_SHADOWS、_MAIN_LIGHT_SHADOWS、_ADDITIONAL_LIGHTS都未激活 StripUnsupportedVariants 主要为剔除不支持的shader变体，剔除情况如下：\nKeyword 说明 剔除条件 DIRLIGHTMAP_COMBINED 烘培开启方向图 LIGHTMAP_ON未激活 _USE_DRAW_PROCEDURAL DrawProcedural GLES20 _MAIN_LIGHT_SHADOWS_CASCADE 主光源的级联阴影 GLES20 _DETAIL_MULX2 两倍的Detail纹理 GLES20 _DETAIL_SCALED 自定义缩放的Detail纹理 GLES20 _CLEARCOAT 透明图层（车漆）效果 GLES20 _CLEARCOATMAP 透明图层（车漆）效果纹理 GLES20 StripUnusedPass 主要为剔除没有在用的Pass，剔除情况如下：\nPass(LightMode) 说明 剔除条件 Meta 生成Lightmapping的Pass 一定剔除 ShadowCaster 阴影捕获Pass ShaderFeatures.MainLightShadows、ShaderFeatures.AdditionalLightShadows未激活 Other 其他剔除情况，剔除情况如下：\nKeyword 说明 剔除条件 _ALPHATEST_ON 启动AlphaTest Lit.shader,并且ShaderFeatures.TerrainHole未激活 Pass(Name) 说明 剔除条件 GBuffer GBuffer的Pass ShaderFeatures.DeferredShading未激活 GBuffer GBuffer的Pass ShaderFeatures.DeferredWithAccurateGbufferNormals激活\n_GBUFFER_NORMALS_OCT未激活 GBuffer GBuffer的Pass ShaderFeatures.DeferredWithoutAccurateGbufferNormals激活\n_GBUFFER_NORMALS_OCT激活 ","ref":"/blog/urp/issue/"},{"title":"HLSL","date":"","description":"HLSL","body":"HLSL的一些基础机制和常用函数\n常用函数 基本运算 名称 用例 描述 最小着色器模型 备注 max max(x, y) 返回x和y中的最大值 1 min min(x, y) 返回x和y中的最小值 1 mul mul(x, y) 返回x和y相乘的结果 1 abs abs(x) 返回x的绝对值 1 round round(x) 返回x的四舍五入结果 1 sqrt sqrt(x) 返回x的平方根 1 rsqrt rsqrt(x) 返回x的平方根的倒数 1 degrees degrees(x) 将弧度x转换为角度 1 redians redians(x) 将角度x转换为弧度 1 noise noise(x) 使用Perlin噪声算法生成-1到1之间的随机数 1 rcp rcp(x) 对分量求倒数 5 幂函数\u0026amp;指数函数\u0026amp;对数函数 名称 用例 描述 最小着色器模型 备注 pow pow(x, y) 返回x的y次幂 1 exp exp(x) 返回e的x次幂 1 exp2 exp2(x) 返回2的x次幂 1 ldexp ldexp(x, exp) 返回x和2的exp次方的乘积 1 log log(x) 返回以e为底，x的对数 1 log10 log10(x) 返回以10为底，x的对数 1 log2 log2(x) 返回以2为底，x的对数 1 frexp frexp(x, out exp) 将浮点数x分解为尾数和指数：$x=ret*2^{exp}$，函数返回尾数，exp返回指数 1 三角函数和双曲函数 名称 用例 描述 最小着色器模型 备注 sin sin(x) 返回x弧度的正弦 1 cos cos(x) 返回x弧度的余弦 1 tan tan(x) 返回x弧度的正切 1 sincos sincos(x, out s, out c) 返回x弧度的正弦和余弦 1 asin asin(x) 返回x弧度的反正弦 1 acos acos(x) 返回x弧度的反余弦 1 atan atan(x) 返回x弧度的反正切 1 atan2 atan2(y, x) 返回y/x的反正切值 1 sinh sinh(x) 返回x弧度的双曲正弦值，$\\frac{e^x-e^{-x}}{2}$ 1 cosh cosh(x) 返回x弧度的双曲余弦值，$\\frac{e^x+e^{-x}}{2}$ 1 tanh tanh(x) 返回x弧度的双曲正切值，$\\frac{e^x-e^{-x}}{e^x+e^{-x}}$ 1 数据范围 名称 用例 描述 最小着色器模型 备注 ceil ceil(x) 返回x的向上取整 1 floor floor(x) 返回x的向下取整 1 step step(x, y) 如果x小于等于y则返回1，否则返回0 1 saturate saturate(x) 将x限定在[0, 1] 1 clamp clamp(x, min, max) 将x限制在[min, max] 1 fmod fmod(x, y) 返回x对y取余的余数 1 frac frac(x) 返回x的小数部分 1 modf modf(x, out ip) 将值x分为小数和整数部分，每个部分的符号与x相同，ip返回整数部分，函数返回小数部分 1 lerp lerp(x, y, s) 使用s在x和y之间线性插值：$x+s(y-x)$ 1 smoothstep smoothstep(min, max, x) 如果x在[min，max]范围内，则返回介于0和1之间的平滑Hermite插值，如果x小于min则返回0，如果x大于max则返回1 1 类型判断 名称 用例 描述 最小着色器模型 备注 all all(x) 如果x的所有分量都不为0，则返回true；否则返回false 1 clip clip(x) 如果x小于0，则丢弃当前像素 1 sign sign(x) 如果x小于0，返回-1，如果x等于0，返回0，如果x大于0，返回1 1 isinf isinf(x) 如果x为正无穷或负无穷，返回true，否则返回false 1 isfinite isfinite(x) 与isinf相反 1 isnan isnan(x) 如果x为NAN，则返回true，否则返回false 1 向量和矩阵 名称 用例 描述 最小着色器模型 备注 length length(v) 返回向量v的长度 1 normalize normalize(v) 返回v的归一化向量 1 distance distance(a, b) 返回a和b之间的距离 1 dot dot(a, b) 返回a和b的点积 1 cross cross(a, b) 返回a和b的叉积 1 determinant determinant(m) 返回矩阵m的行列式的值 1 transpose transpose(m) 返回m的转置 1 光线运算 名称 用例 描述 最小着色器模型 备注 reflect reflect(i, n) 以i为入射方向，n为法线的反射光 1 refrect refrect(i, n, ri) 以i为入射方向，n为法线方向，ri为折射率的折射光 1 lit lit(n_dot_l, n_dot_h, m) 输入归一化的法线和光向量的点积，半角向量和法线的点积，高光指数，返回光照向量（环境光，漫反射，高光，1） 1 faceforward faceforward(n, i, ng) 返回面向视图方向的曲面法向量 1 纹理查找 名称 用例 描述 最小着色器模型 备注 tex1D tex1D(s, t) 返回s在t处的值 1 tex1D tex1D(s, t, ddx, ddy) 使用偏导数对2D纹理进行采样以选择Mip级别 1 tex1Dproj tex1Dproj(s, t) 将xyz除以w，然后进行纹理查找 1 tex1Dlod tex1Dlod(s, t) 使用lod查找纹理s在t.w处的值 1 tex1Dbias tex1Dbias(s, t) 将t.w决定的某个Mip层偏置后的纹理查找 1 tex1Dgrad tex1Dgrad(s, t, ddx, ddy) 使用微分并指定Mip层的纹理查找 1 ","ref":"/blog/shader/hlsl/"},{"title":"YooAsset插件","date":"","description":"学习YooAsset插件和分析","body":"YooAsset是一个Unity资源系统，集合资源打包、分包、更新、加载等。\n信息 官网：YooAsset 版本：1.4.2 源码：https://github.com/tuyoogame/YooAsset 构建 收集 检测配置合法性 收集所有Package的资源（遍历所有的Group，然后再遍历所有的Collector） AssetBundleCollectorSettingData.Setting.GetPackageAssets(buildMode, packageName); 剔除未被引用的依赖资源 录入所有收集器收集的资源 录入相关依赖的资源 记录关键信息 填充主动收集资源的依赖列表 计算完整的资源包名 移除不参与构建的资源 构建资源包 Runtime 初始化 YooAssets初始化。 创建驱动器YooAssetsDriver用于调度系统的Update 创建远程调试器RemoteDebuggerInRuntime用于调试加载情况 初始化异步系统OperationSystem // 初始化资源系统 YooAssets.Initialize(); 创建Package。 创建package 设置为默认的package // 创建默认的资源包 var package = YooAssets.CreateAssetsPackage(\u0026#34;DefaultPackage\u0026#34;); // 设置该资源包为默认的资源包，可以使用YooAssets相关加载接口加载该资源包内容。 YooAssets.SetDefaultAssetsPackage(package); 初始化资源系统（Editor模拟） EditorSimulateModeHelper.SimulateBuild会调用AssetBundleSimulateBuilder构建资源清单 再把Parameters传入package进行资源清单初始化 package根据mode创建EditorSimulateModeImpl，这是包含了IPlayModeServices和IBundleServices具体实现的集合。 package创建AssetSystemImpl，然后进行初始化。 EditorSimulateModeImpl进行初始化。 调用EditorSimulateModeInitializationOperation加载清单，并且设置清单到EditorSimulateModeImpl var createParameters = new EditorSimulateModeParameters(); createParameters.SimulatePatchManifestPath = EditorSimulateModeHelper.SimulateBuild(packageName); InitializationOperation initializationOperation = package.InitializeAsync(createParameters); 初始化资源系统（单机模式） 把Parameters传入package进行资源清单初始化 package根据mode创建OfflinePlayModeImpl，这是包含了IPlayModeServices和IBundleServices具体实现的集合。 package创建AssetSystemImpl，然后进行初始化。 OfflinePlayModeImpl进行初始化。 调用OfflinePlayModeInitializationOperation 获取Package版本号 加载清单。 设置清单到OfflinePlayModeImpl 校验清单的资源包，将正确的补丁放入CacheSystem var createParameters = new OfflinePlayModeParameters(); InitializationOperation initializationOperation = package.InitializeAsync(createParameters); 初始化资源系统（联机模式） 把Parameters传入package进行资源清单初始化 package根据mode创建HostPlayModeImpl，这是包含了IPlayModeServices和IBundleServices具体实现的集合。 package创建AssetSystemImpl，然后进行初始化。 HostPlayModeImpl进行初始化。 调用HostPlayModeInitializationOperation 获取补丁水印（安装包版本号和补丁版本号），如果水印不一致，则清空缓存目录。 获取缓存目录Package版本号，如果存在，则加载和解析缓存目录清单 在缓存目录清单加载失败（版本号不对、hash值不对、清单不存在等），则获取安装包Package版本号，并且把版本号和清单写入到缓存目录。最后再加载安卓包清单。 设置清单到HostPlayModeImpl 校验清单的资源包，将正确的补丁放入CacheSystem var createParameters = new OfflinePlayModeParameters(); InitializationOperation initializationOperation = package.InitializeAsync(createParameters); 更新 //更新Package版本信息 var operation = package.UpdatePackageVersionAsync(); yield return operation; //更新Package资源清单 package.UpdatePackageManifestAsync(operation.PackageVersion); //创建下载器 var downloader = YooAssets.CreatePatchDownloader(downloadingMaxNum, failedTryAgain); 只有联机模式才有更新系统\nHostPlayModeUpdatePackageVersionOperation请求远端版本号信息。 HostPlayModeUpdatePackageManifestOperation更新补丁清单。 加载Cache清单，判断版本号是否为最新 当版本号不是最新时，下载远端清单到Cache目录。 重新加载Cache清单。 校验清单的资源包，将正确的补丁放入CacheSystem PatchDownloaderOperation下载补丁（不包含已有缓存、内置资源） 清除过期的补丁文件 扩展 由于代码比较简单易懂，并且框架解耦的较好，扩展性比较好。\n更新 目前热更方式为CDN获取版本信息，可以增加后台模式，以适应后台更新的方案。\n//AssetsPackage.InitializeAsync() if (...) { ... } else if (_playMode == EPlayMode.ServerPlayMode) { var serverPlayModeImpl = new ServerPlayModeImpl(); ... } 疑问 覆盖安装情况下，资源是否正常？ 会通过水印判断安装包是否有变更，如果安装包变更了，则清除Cache目录\n断点续传是否会出现缺漏的问题？ 每次会对文件计算hash值进行校验。没有缺漏问题。\n热更是否要在Cache增加一份副本？ 安装包的内容只有一份。热更时会使用IsBuildinPatchBundle进行判断剔除。\nCDN需要全量补丁？ 发布没有差异补丁的概念，所以都是全量补丁\n对比 Addressable Group与Addressable的差不多，都是用于资源分组使用 没有了自定义Entry的概念，取而代之增加了Collector对资源进行收集设置。 收集器的地址保存的是字符串，移动文件夹时会出现丢失的问题。 获取Entry地址和寻址信息需要手动拼写 Tags只能对Group设置，无法只对Collector和Entry设置 Group相对于Addressable去除了很多独立设置，无法对AB进行独立设置压缩方式，命名方式等 地址和寻址两套方式可以选择使用 支持旧的构建模式和SBP模式 配置有Json和Bytes两种，bytes只是简单序列化了，并没有做压缩处理。 Group之上还增加了Package的概念，用于构建时可以分情况构建。 有多种构建模式，例如演练和模拟模式可以方便调试 有调试器和报告查看工具 更新地址需要运行设置。 支持构建原文件 Editor模拟模式，需要每次运行时调用构建，需要生成列表清单。目前只有收集到的资源需要生成清单，理论上速度应该不慢。 构建时才会检查资源是否重复收集 Operation采用的是Update来处理，没有采用协程。Operation通过状态来去区分任务，需要等待子Operation完成来改变状态。 有加密接口。Android采用加密只能使用偏移头文件的方式，如果采用其他方式，将无法加载SteamingAsset目录资源。 问题 在AssetBundleFileLoader加载失败时会调用CacheSystem.DiscardFile清除，但实际上会清除整个Cache目录！！！ 缺少SpriteAtlas打包 加载场景时，会自动清空资源引用计数，导致对象池中的对象丢失资源引用。 只有在加载场景时才会检测资源引用计数 优点 代码结构较为简单，容易扩展 多线程下载 多线程校验文件 开箱即用 缺点 每次都需要校验文件，全量计算文件Hash，数量一多会比较耗时 收集器需要填写配置，有资源需要特殊处理时，比较难处理 补丁为全量资源上传CDN，如果改成增量补丁，并且按版本分开目录，需要扩展新的mode。 寻址的Key值无法自定义，相同文件名会出现Key重复的问题。 ","ref":"/blog/plugin/yooasset/"},{"title":"构建iOS包","date":"","description":"构建iOS包","body":"在构建iOS包时，遇到了挺多问题，因此记录下来，以备不时之需\n环境 Unity:2020.3.26f1 XCode:13.2.1(13C100) 导出xcodeproj 使用UnityEditor.BuildPipeline.BuildPlayer构建即可，然后就导出xcodeproj。\n设置xcodeproj配置 PBXProject工具 PBXProject是Unity用于修改导出的xcode工程参数的工具。\nP.S.需要安装iOSSupport\n//初始化PBXProject UnityEditor.iOS.Xcode.PBXProject project = new UnityEditor.iOS.Xcode.PBXProject(); string projectName = UnityEditor.iOS.Xcode.PBXProject.GetPBXProjectPath(projectPath); //使用BuildPlayer的构建目录地址获取PBX项目地址 project.ReadFromFile(projectName); //读取项目配置文件 //修改配置的逻辑.... project.WriteToFile(projectName); //把修改后的配置写入 添加引用库 某些第三方SDK需要加入引用的库。\n例如Bugly，需要增加以下库：\nlibz.tbd libc++.tbd Security.framework SystemConfiguration.framework JavaScriptCore.framework 然后可以使用AddFrameworkToProject进行添加这些库。\n//先获取UnityFramework的targetGUID，用于指定需要添加库的配置 string frameworkGUID = project.GetUnityFrameworkTargetGuid(); project.AddFrameworkToProject(frameworkGUID, \u0026#34;libz.tbd\u0026#34;, false); project.AddFrameworkToProject(frameworkGUID, \u0026#34;libc++.tbd\u0026#34;, false); ... 设置属性 需要设置某些构建属性时，需要用到SetBuildProperty方法。\n例如关闭Bitcode\n//获取UnityMain和UnityFramework的targetGUID，用于指定需要修改属性的配置 string mainTargetGUID = project.GetUnityMainTargetGuid(); string frameworkGUID = project.GetUnityFrameworkTargetGuid(); //Bitcode需要都关闭 project.SetBuildProperty(mainTargetGUID, \u0026#34;ENABLE_BITCODE\u0026#34;, \u0026#34;No\u0026#34;); //用于开启关闭Bitcode project.SetBuildProperty(frameworkGUID, \u0026#34;ENABLE_BITCODE\u0026#34;, \u0026#34;No\u0026#34;); //用于开启关闭Bitcode //发布版时，需要修改签名类型 project.SetBuildProperty(mainTargetGUID, \u0026#34;CODE_SIGN_IDENTITY\u0026#34;, \u0026#34;Apple Distribution\u0026#34;); //用于设置成发布状态 project.SetBuildProperty(mainTargetGUID, \u0026#34;CODE_SIGN_IDENTITY[sdk=iphoneos*]\u0026#34;, \u0026#34;Apple Distribution\u0026#34;); //用于设置成发布状态 project.SetBuildProperty(mainTargetGUID, \u0026#34;PROVISIONING_PROFILE_SPECIFIER\u0026#34;, m_Setting.ProvisioningProfileName); //需要设置ProvisioningProfile ExportOptions Method：方式 app-store enterprise ad-hoc development BundleID：包名 ProvisioningProfile：证书名字 TeamID：证书的TeamID Certificate：签名证书 \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34; -//Apple//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;compileBitcode\u0026lt;/key\u0026gt; \u0026lt;false/\u0026gt; \u0026lt;key\u0026gt;destination\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;export\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;manageAppVersionAndBuildNumber\u0026lt;/key\u0026gt; \u0026lt;false/\u0026gt; \u0026lt;key\u0026gt;method\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;${METHOD}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;provisioningProfiles\u0026lt;/key\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;${BUNDLE_ID}\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;${PROVISIONING_PROFILE}\u0026lt;/string\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;key\u0026gt;signingCertificate\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;${CERTIFICATE}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;signingStyle\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;manual\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;stripSwiftSymbols\u0026lt;/key\u0026gt; \u0026lt;true/\u0026gt; \u0026lt;key\u0026gt;teamID\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;${TEAM_ID}\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;thinning\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;\u0026amp;lt;none\u0026amp;gt;\u0026lt;/string\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 隐私清单 参考：https://blog.csdn.net/qq_37672438/article/details/137133195\n参考：https://juejin.cn/post/7365723860997390372\n错误处理 环境错误 The data couldn’t be read because it isn’t in the correct format\nhttps://www.jianshu.com/p/103f414fa870\nhttps://stackoverflow.com/questions/58272706/error-exportarchive-the-data-couldn-t-be-read-because-it-isn-t-in-the-correct\nsqlite3环境问题导致的报错，执行如下指令即可：\ngem list | grep sqlite3 gem install sqlite3 --platform=ruby rvm use system --default 类型错误 Error Domain=IDEProfileLocatorErrorDomain Code=4 \u0026ldquo;No \u0026ldquo;iOS App Development\u0026rdquo; profiles for team \u0026lsquo;*****\u0026rsquo; \u0026hellip;..\n确保provisioning profile中填入的类型正确\n授权问题 \u0026ldquo;error: \u0026ldquo;Unity-iPhone\u0026rdquo; requires a provisioning profile. Select a provisioning profile in the Signing \u0026amp; Capabilities editor. (in target \u0026lsquo;Unity-iPhone\u0026rsquo; from project \u0026lsquo;Unity-iPhone\u0026rsquo;)\u0026rdquo;\n一般是没有登录provisioning profile对应的开发者账号，或者是没有安装provisioning profile对应的Capabilities\n","ref":"/blog/publish/buildios/"},{"title":"UnityEvent引起的内存泄漏","date":"","description":"UnityEvent引起的内存泄漏","body":"一个由UnityEvent缓存机制引起的内存泄漏问题\n前言 笔者在开发项目时，发现在xLua Dispose时总是会有DelegateBridge没有移除的情况，而排查了一轮，发现就算是一个简单界面也会出现这种情况。\n后来经过一轮排查，发现Button的点击事件触发了，就会出现无法移除DelegateBridgeBase，然后翻看了xLua的issue（xLua#139）发现很早就有这个问题，而且也有人提供了解决方案。\n问题原因 首先这个问题归根到底是由UnityEvent的缓存机制导致：\nUnity在设计UnityEvent时，为其加了缓存机制，也就是上一次调用过的Calls会缓存起来，然后在增加/删除callback时，对缓存设置脏标记。然后在下一次触发事件时，在有变动时才会重新生成Calls。\n//这里截取Unity 2020.3.x版本UnityEvent.CS \u0026lt;InvokableCallList\u0026gt;类的片段 //与Issue中的版本代码有点差异，但机制大致相同 public void RemoveListener(object targetObj, MethodInfo method) { var toRemove = new List\u0026lt;BaseInvokableCall\u0026gt;(); for (int index = 0; index \u0026lt; m_RuntimeCalls.Count; index++) { if (m_RuntimeCalls[index].Find(targetObj, method)) toRemove.Add(m_RuntimeCalls[index]); } m_RuntimeCalls.RemoveAll(toRemove.Contains); m_NeedsUpdate = true; } ... public List\u0026lt;BaseInvokableCall\u0026gt; PrepareInvoke() { if (m_NeedsUpdate) { m_ExecutingCalls.Clear(); m_ExecutingCalls.AddRange(m_PersistentCalls); m_ExecutingCalls.AddRange(m_RuntimeCalls); m_NeedsUpdate = false; } return m_ExecutingCalls; } 那么问题就来，由于在每次触发（Invoke）事件前，才会重新生成Calls,就算之前已经对callback进行了Remove了，只要没有调用，缓存还会保留已经移除的函数。\n问题危害 正常流程 在xLua框架中，lua需要监听C#的事件，需要把function(lua)设置到LUA_REGISTRYINDEX，并且把引用给到C#，C#再生成Delegate，然后把Delegate和引用封装到DelegateBridge(C#)对象中。\n这样，只要把此Delegate绑定到对应的事件中，当事件触发后，就会调用此Delegate，再由DelegateBridge根据引用获取并调用function(lua)。\n由于DelegateBridge只以弱引用的方式保存，所以当移除事件后，Delegate只与对应的DelegateBridge有引用关系，所以在下一轮GC即可销毁掉DelegateBridge，从而接触对应引用的function(lua)（将function从LUA_REGISTRYINDEX中释放掉）。\n这个时候，lua gc就可以把function以及对应upvalue销毁（假设没有任何其他对象引用）。\n泄漏情况 上述都是function(lua)与Delegate绑定和释放的正常流程。而在UnityEvent内存泄漏的情况下，又会变得怎样呢？\n这里我们加入比较常见的情景：\nlocal item = {} item.name = \u0026#34;name\u0026#34; item.button = .... --获取Button对象 item.button.onClick:AddListener(function () print(item.name) end) ...--一顿操作 item.button.onClick:RemoveAllListeners() 根据前文，如果我们在移除前触发了点击事件，那么UnityEvent就会缓存了Delegate，从而保留了DelegateBridge。这个时候唯一办法就是等button释放掉，顺带把UnityEvent也释放，这样DelegateBridge才能给GC回收。\n但是，我们button却给lua的table对象引用了，而这个table又是闭包函数的upvalue值，而最糟糕的是，这个闭包函数却给DelegateBridge引用了（通过LUA_REGISTRYINDEX）。所以，这个table以及button(userdata)都无法给GC回收。\n那么现在就形成了一个死结，而这个死结只要有任何一处解开就可以完全解开了，但现在处处都无法解开。\n解决方案 调用Invoke 根据xLua#139，可以在RemoveAllListener之后，手动调用一次Invoke，这样就可以清除掉Calls。\n但此方法有个问题，假设Button在Inspector界面上绑定了持久化事件，就会多触发一次事件，可能会有意想不到的bug出现。所以不建议使用\n反射 根据xLua#139，其实可以通过反射去释放掉UnityEvent中的缓存。\nprivate static MethodInfo prepareInvoke; public static void ReleaseUnusedListeners(this UnityEventBase unityEventBase) { if (prepareInvoke == null) { BindingFlags flag = BindingFlags.Instance | BindingFlags.NonPublic; Type type = unityEventBase.GetType(); prepareInvoke = type.GetMethod(\u0026#34;PrepareInvoke\u0026#34;, flag); } prepareInvoke.Invoke(unityEventBase, null); } ... item.button.onClick:RemoveAllListeners() item.button.onClick:ReleaseUnusedListeners() 笔者在issue基础上进行了优化。\n此方案副作用小，只要不忘记调用，就可以释放掉对应事件。笔者也是采用这套方案。\n这里要注意的是，如果是采用Generate的方式，需要增加ButtonClickedEvent等参数的接口，不然xlua会找不到方法。\n升级版本 UnityEvent这个内存泄漏的问题，在Unity 2021.2.x版本就已经修复了（吐槽：这个bug在2017年前就已经存在了）。\nScripting: Fixed a memory leak happening when removing listeners from a UnityEvent that is never raised afterwards. (1303095)\n所以可以通过升级版进行修复。\npublic void RemoveListener(object targetObj, MethodInfo method) { var toRemove = new List\u0026lt;BaseInvokableCall\u0026gt;(); for (int index = 0; index \u0026lt; m_RuntimeCalls.Count; index++) { if (m_RuntimeCalls[index].Find(targetObj, method)) toRemove.Add(m_RuntimeCalls[index]); } m_RuntimeCalls.RemoveAll(toRemove.Contains); // removals are done synchronously to avoid leaks var newExecutingCalls = new List\u0026lt;BaseInvokableCall\u0026gt;(m_PersistentCalls.Count + m_RuntimeCalls.Count); newExecutingCalls.AddRange(m_PersistentCalls); newExecutingCalls.AddRange(m_RuntimeCalls); m_ExecutingCalls = newExecutingCalls; m_NeedsUpdate = false; } ","ref":"/blog/unity3d/unityeventmemoryleak/"},{"title":"C#知识点-反射","date":"","description":"收纳一些常用的C#知识点","body":"收纳归总一些常用的C#技巧或者知识点\nType.IsByRef 当参数的类型为引用传递时，IsByRef为True。此时要获得最终类型需要调用GetElementType()。\nprivate class CustomTypeClass { //Console：type name:Int32 isByRef:False public void Fun(int value) { } //Console：type name:Int32\u0026amp; isByRef:True elementType:Int32 public void Fun(ref int value) { } //Console：type name:Object isByRef:False public void Fun(object obj) { } //Console：type name:Object\u0026amp; isByRef:True elementType:Object public void Fun(ref object obj) { } //Console：type name:Int32[] isByRef:False public void Fun(int[] intarray) { } //Console：type name:Int32[]\u0026amp; isByRef:True elementType:Int32[] public void Fun(ref int[] intarray) { } } static void Main(string[] args) { MethodInfo[] methodInfos = typeof(CustomTypeClass).GetMethods(); foreach (var methodInfo in methodInfos) { ParameterInfo[] parameters = methodInfo.GetParameters(); foreach (var parameter in parameters) { var parameterType = parameter.ParameterType; Debug.WriteLine(string.Format(\u0026#34;method name:{0}\u0026#34;, methodInfo.Name)); LogType(parameterType); } } } private static void LogType(Type type) { if (type.IsByRef) { Debug.WriteLine(string.Format(\u0026#34;type name:{0} isByRef:{1} elementType:{2}\u0026#34;, type.Name, type.IsByRef, type.GetElementType().Name)); } else { Debug.WriteLine(string.Format(\u0026#34;type name:{0} isByRef:{1}\u0026#34;, type.Name, type.IsByRef)); } } ","ref":"/blog/csharp/reflection/"},{"title":"Github Action自动化部署Hugo","date":"","description":"教你如何使用Github Action自动化部署Hugo静态页面","body":"每次用Hugo写完Blog，都要重新编译，然后提交到对应的仓库，重复并且繁琐。所以，这里就教大家如何使用Github的自动化构建工具-Action，自动编译部署到Github Pages上。\n由于本文只是教如何使用Github Action，因此，Hugo的调试和部署，不额外拓展。\nRepositorie 创建两个仓库用于后续Action使用\nSource Repositorie 创建一个{xxxxx}.github.source P.S.{xxxxx}为自己的域名。\nSource仓库，是用来放置Hugo源码的。 Page Repositorie 创建一个{xxxxx}.github.io P.S.{xxxxx}为自己的域名。如果使用Github Pages的域名，请与Github账号名一致\nPage仓库用于放置生成后的Html页面 Github Action 使用Action自动化部署到Pages\nCreate ssh-keygen // 使用命令生成公钥和密钥 // {email}为你的邮箱地址 // 注意：不要输入密码，直接回车即可，因为有密码的话，Action运行时会卡在输入密码的步骤 ssh-keygen -t rsa -b 4096 -C \u0026#34;{email}\u0026#34; 这样，本地就会产生一个公钥和一个密钥\n记住，一定要生成4096以上，不然后续Action时无法正常连接Pages仓库\nSource Repositorie 进入\u0026quot;Settings/secrets/Actions\u0026quot; 点击\u0026quot;New repository secret\u0026quot; Title填写\u0026quot;ACTIONS_DEPLOY_KEY\u0026quot; Value填写私钥文件的内容 确定 Pages Repositorie 进入\u0026quot;Settings/Deploy keys\u0026quot; 点击\u0026quot;Add deploy key\u0026quot; Title填写\u0026quot;Public of ACTIONS_DEPLOY_KEY\u0026quot; Key填写.pub文件（公钥）的内容 勾选\u0026quot;Allow write access\u0026quot; 确定 Add Action 在源码仓库的\u0026quot;.github/workflows\u0026quot;下已经有\u0026quot;gh-pages.yml\u0026quot;用于生成Pages\n如果没有，请完整阅读\u0026quot;Create Action\u0026quot;。\nCreate Action 参考actions-hugo\nname: github pages on: push: branches: - master # Set a branch to deploy jobs: deploy: runs-on: ubuntu-18.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#39;0.74.2\u0026#39; extended: true - name: Setup Node uses: actions/setup-node@v1 with: node-version: \u0026#39;12.x\u0026#39; - name: Cache dependencies uses: actions/cache@v1 with: path: ~/.npm key: ${{ runner.os }}-node-${{ hashFiles(\u0026#39;**/package-lock.json\u0026#39;) }} restore-keys: | ${{ runner.os }}-node- - run: npm ci - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} external_repository: publish_dir: ./public publish_branch: master # deploying cname: Change Action hugo-version为Hugo版本，尽量改成与自己调试的环境一直版本 修改deploy_key为\u0026quot;${{ secrets.ACTIONS_DEPLOY_KEY }}\u0026quot; ACTIONS_DEPLOY_KEY为刚才添加的密钥\n修改external_repository为放置Pages的Repositorie地址 修改publish_branch为Page仓库的主干，例如master或者main 增加cname为你的域名，用于域名解析。P.S.如果没有，则注释或者删除此行 Deploy 当你在Source Repositorie提交修改时，“github pages”这个action就会自动启动，然后初始化环境、编译、部署，实现完全的自动化。而你，只需要在提交文章几分钟后，刷新一下页面。\n","ref":"/blog/git/githubaction-hugo/"},{"title":"","date":"","description":"","body":"","ref":"/blog/lua/hotreload/"},{"title":"联络","date":"","description":"","body":"","ref":"/contact/"}]